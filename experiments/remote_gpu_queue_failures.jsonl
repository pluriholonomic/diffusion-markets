{"done_ts": "2025-12-27T03:45:36Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_diffsample_scalar_s16_mc8_20251227_022603", "log": "remote_logs/pm_diffsample_scalar_s16_mc8_20251227_022603.log", "pid": 749093, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4035, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1495, in cmd_pm_diff_sample\n    model = ContinuousDiffusionForecaster.load(str(args.model_path), device=str(args.device))\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/diffusion_core.py\", line 259, in load\n    payload = torch.load(path, map_location=\"cpu\")\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/serialization.py\", line 1529, in load\n    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL forecastbench.models.diffusion_logit.LogitDiffusionSpec was not an allowed global by default. Please use `torch.serialization.add_safe_globals([forecastbench.models.diffusion_logit.LogitDiffusionSpec])` or the `torch.serialization.safe_globals([forecastbench.models.diffusion_logit.LogitDiffusionSpec])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n", "ts": "2025-12-27T03:47:04Z"}
{"done_ts": "2025-12-27T03:47:39Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_diffsample_scalar_s16_mc32_20251227_022603", "log": "remote_logs/pm_diffsample_scalar_s16_mc32_20251227_022603.log", "pid": 751043, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4034, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1495, in cmd_pm_diff_sample\n    model = ContinuousDiffusionForecaster.load(str(args.model_path), device=str(args.device))\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/diffusion_core.py\", line 259, in load\n    payload = torch.load(path, map_location=\"cpu\")\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/serialization.py\", line 1529, in load\n    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL forecastbench.models.diffusion_logit.LogitDiffusionSpec was not an allowed global by default. Please use `torch.serialization.add_safe_globals([forecastbench.models.diffusion_logit.LogitDiffusionSpec])` or the `torch.serialization.safe_globals([forecastbench.models.diffusion_logit.LogitDiffusionSpec])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n", "ts": "2025-12-27T03:48:55Z"}
{"done_ts": "2025-12-27T03:47:43Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_diffsample_scalar_s32_mc8_20251227_022603", "log": "remote_logs/pm_diffsample_scalar_s32_mc8_20251227_022603.log", "pid": 751299, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4034, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1495, in cmd_pm_diff_sample\n    model = ContinuousDiffusionForecaster.load(str(args.model_path), device=str(args.device))\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/diffusion_core.py\", line 259, in load\n    payload = torch.load(path, map_location=\"cpu\")\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/serialization.py\", line 1529, in load\n    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL forecastbench.models.diffusion_logit.LogitDiffusionSpec was not an allowed global by default. Please use `torch.serialization.add_safe_globals([forecastbench.models.diffusion_logit.LogitDiffusionSpec])` or the `torch.serialization.safe_globals([forecastbench.models.diffusion_logit.LogitDiffusionSpec])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n", "ts": "2025-12-27T03:49:10Z"}
{"done_ts": "2025-12-27T03:49:45Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_diffsample_scalar_s32_mc32_20251227_022603", "log": "remote_logs/pm_diffsample_scalar_s32_mc32_20251227_022603.log", "pid": 753679, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4034, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1495, in cmd_pm_diff_sample\n    model = ContinuousDiffusionForecaster.load(str(args.model_path), device=str(args.device))\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/diffusion_core.py\", line 259, in load\n    payload = torch.load(path, map_location=\"cpu\")\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/serialization.py\", line 1529, in load\n    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL forecastbench.models.diffusion_logit.LogitDiffusionSpec was not an allowed global by default. Please use `torch.serialization.add_safe_globals([forecastbench.models.diffusion_logit.LogitDiffusionSpec])` or the `torch.serialization.safe_globals([forecastbench.models.diffusion_logit.LogitDiffusionSpec])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n", "ts": "2025-12-27T03:50:56Z"}
{"done_ts": "2025-12-27T03:51:33Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_diffsample_scalar_s64_mc8_20251227_022603", "log": "remote_logs/pm_diffsample_scalar_s64_mc8_20251227_022603.log", "pid": 755387, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4034, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1495, in cmd_pm_diff_sample\n    model = ContinuousDiffusionForecaster.load(str(args.model_path), device=str(args.device))\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/diffusion_core.py\", line 259, in load\n    payload = torch.load(path, map_location=\"cpu\")\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/serialization.py\", line 1529, in load\n    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL forecastbench.models.diffusion_logit.LogitDiffusionSpec was not an allowed global by default. Please use `torch.serialization.add_safe_globals([forecastbench.models.diffusion_logit.LogitDiffusionSpec])` or the `torch.serialization.safe_globals([forecastbench.models.diffusion_logit.LogitDiffusionSpec])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n", "ts": "2025-12-27T03:52:45Z"}
{"done_ts": "2025-12-27T03:53:21Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_diffsample_scalar_s64_mc32_20251227_022603", "log": "remote_logs/pm_diffsample_scalar_s64_mc32_20251227_022603.log", "pid": 756774, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4034, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1495, in cmd_pm_diff_sample\n    model = ContinuousDiffusionForecaster.load(str(args.model_path), device=str(args.device))\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/diffusion_core.py\", line 259, in load\n    payload = torch.load(path, map_location=\"cpu\")\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/serialization.py\", line 1529, in load\n    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL forecastbench.models.diffusion_logit.LogitDiffusionSpec was not an allowed global by default. Please use `torch.serialization.add_safe_globals([forecastbench.models.diffusion_logit.LogitDiffusionSpec])` or the `torch.serialization.safe_globals([forecastbench.models.diffusion_logit.LogitDiffusionSpec])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n", "ts": "2025-12-27T03:54:32Z"}
{"done_ts": "2025-12-27T03:55:47Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_bundle_difftrain_topic4_m5000_20251227_022603", "log": "remote_logs/pm_bundle_difftrain_topic4_m5000_20251227_022603.log", "pid": 758495, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n  warnings.warn(\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'volume_q5'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4034, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'volume_q5'\n[bundle_diffusion] step 200/4000  loss=0.706213\n[bundle_diffusion] step 400/4000  loss=0.321749\n[bundle_diffusion] step 600/4000  loss=0.252974\n[bundle_diffusion] step 800/4000  loss=0.209319\n[bundle_diffusion] step 1000/4000  loss=0.192471\n[bundle_diffusion] step 1200/4000  loss=0.199870\n[bundle_diffusion] step 1400/4000  loss=0.170067\n[bundle_diffusion] step 1600/4000  loss=0.151044\n[bundle_diffusion] step 1800/4000  loss=0.139231\n[bundle_diffusion] step 2000/4000  loss=0.133088\n[bundle_diffusion] step 2200/4000  loss=0.119201\n[bundle_diffusion] step 2400/4000  loss=0.113949\n[bundle_diffusion] step 2600/4000  loss=0.086623\n[bundle_diffusion] step 2800/4000  loss=0.084304\n[bundle_diffusion] step 3000/4000  loss=0.114159\n[bundle_diffusion] step 3200/4000  loss=0.077423\n[bundle_diffusion] step 3400/4000  loss=0.114889\n[bundle_diffusion] step 3600/4000  loss=0.070732\n[bundle_diffusion] step 3800/4000  loss=0.090666\n[bundle_diffusion] step 4000/4000  loss=0.058598\n", "ts": "2025-12-27T03:56:26Z"}
{"done_ts": "2025-12-27T04:36:06Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "turtel_compare_existing_diff", "log": "remote_logs/turtel_compare_existing_diff.log", "pid": 767421, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4034, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3199, in cmd_turtel_compare\n    results = run_turtel_comparison(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/turtel_comparison.py\", line 389, in run_turtel_comparison\n    summary = diffusion_vs_turtel_summary(turtel_metrics, our_metrics)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/turtel_comparison.py\", line 217, in diffusion_vs_turtel_summary\n    \"winner\": \"diffusion\" if diffusion_metrics[\"brier\"] < turtel_metrics.get(\"brier\", float(\"inf\")) else \"turtel\",\nTypeError: '<' not supported between instances of 'float' and 'str'\nRunning Turtel comparison on 1007 samples\n", "ts": "2025-12-27T04:37:31Z"}
{"done_ts": "2025-12-27T04:40:02Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_difftrain_turtel_ready", "log": "remote_logs/pm_difftrain_turtel_ready.log", "pid": 769710, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4034, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 200/4000  loss=1.039314  lr=2.00e-04\n[diffusion] step 400/4000  loss=0.653949  lr=1.97e-04\n[diffusion] step 600/4000  loss=0.507328  lr=1.92e-04\n[diffusion] step 800/4000  loss=0.462129  lr=1.85e-04\n[diffusion] step 1000/4000  loss=0.424248  lr=1.75e-04\n[diffusion] step 1200/4000  loss=0.399197  lr=1.63e-04\n[diffusion] step 1400/4000  loss=0.393562  lr=1.50e-04\n[diffusion] step 1600/4000  loss=0.364794  lr=1.35e-04\n[diffusion] step 1800/4000  loss=0.352390  lr=1.20e-04\n[diffusion] step 2000/4000  loss=0.337336  lr=1.04e-04\n[diffusion] step 2200/4000  loss=0.331803  lr=8.79e-05\n[diffusion] step 2400/4000  loss=0.323464  lr=7.22e-05\n[diffusion] step 2600/4000  loss=0.315166  lr=5.71e-05\n[diffusion] step 2800/4000  loss=0.320606  lr=4.32e-05\n[diffusion] step 3000/4000  loss=0.309089  lr=3.07e-05\n[diffusion] step 3200/4000  loss=0.300216  lr=2.01e-05\n[diffusion] step 3400/4000  loss=0.293629  lr=1.15e-05\n[diffusion] step 3600/4000  loss=0.290590  lr=5.15e-06\n[diffusion] step 3800/4000  loss=0.282896  lr=1.29e-06\n[diffusion] step 4000/4000  loss=0.275916  lr=0.00e+00\n", "ts": "2025-12-27T04:40:52Z"}
{"done_ts": "2025-12-27T03:02:55Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_difftrain_optimized_v1", "log": "remote_logs/pm_difftrain_optimized_v1.log", "pid": 776095, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.81it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.75it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.73it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.73it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.70it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.68it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.66it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.91it/s]\n", "ts": "2025-12-27T04:51:14Z"}
{"done_ts": "2025-12-27T03:07:47Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_hybrid_train_v1", "log": "remote_logs/pm_hybrid_train_v1.log", "pid": 778932, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 1000 rows from /root/polymarket_data/derived/gamma_yesno_ready.parquet\nTrain: 800, Test: 200\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:04,  1.74it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.70it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.68it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.67it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.67it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.66it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.66it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.99it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.79it/s]\n", "ts": "2025-12-27T04:55:34Z"}
{"done_ts": "2025-12-27T11:58:45Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "pm_hybrid_train_v3_gpu1", "log": "remote_logs/pm_hybrid_train_v3_gpu1.log", "pid": 791402, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 2000 rows from /root/polymarket_data/derived/gamma_yesno_ready.parquet\nTrain: 1600, Test: 400\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:04,  1.73it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.68it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:03,  1.66it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.65it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:03<00:01,  1.65it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.65it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.64it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.98it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.77it/s]\nAR train: mean=0.336, std=0.188\nAR test: mean=0.351, std=0.179\n\n=== Step 2: Text Embeddings ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.81it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.76it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.73it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.73it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.72it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.72it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.72it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.95it/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4034, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3096, in cmd_pm_hybrid_train\n    train_meta = diff_head.train_loop(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/ar_diffusion_hybrid.py\", line 227, in train_loop\n    pred = self.forward(x_t_t, t_t, c_t)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/ar_diffusion_hybrid.py\", line 158, in forward\n    x = self.input_proj(inp)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 134, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (512x5634 and 5633x512)\nEmbeddings: train=(1600, 5120), test=(400, 5120)\n\n=== Step 3: Train Diffusion Refinement ===\n", "ts": "2025-12-27T12:03:10Z"}
{"done_ts": "2025-12-27T12:22:52Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_hybrid_train_v2", "log": "remote_logs/pm_hybrid_train_v2.log", "pid": 850474, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 1000 rows from /root/polymarket_data/derived/gamma_yesno_ready.parquet\nTrain: 800, Test: 200\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.81it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.76it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.73it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.73it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.72it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.72it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.72it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.07it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.85it/s]\n", "ts": "2025-12-27T12:25:21Z"}
{"done_ts": "2025-12-27T21:10:06Z", "event": "failed", "exit_code": 2, "gpu": 1, "id": "pm_ar_baseline_gpu1", "log": "remote_logs/pm_ar_baseline_gpu1.log", "pid": 894436, "tail": "usage: forecastbench pm_rlvr_eval [-h] --dataset-path DATASET_PATH\n                                  [--run-name RUN_NAME]\n                                  [--max-examples MAX_EXAMPLES]\n                                  [--text-cols TEXT_COLS]\n                                  [--pred-col PRED_COL] [--bins BINS]\n                                  [--transaction-cost TRANSACTION_COST]\n                                  [--B B] [--trading-mode TRADING_MODE]\n                                  [--group-cols GROUP_COLS] --base-model\n                                  BASE_MODEL --adapter-path ADAPTER_PATH\n                                  [--K K] [--L L] [--agg AGG] [--seed SEED]\n                                  [--device DEVICE] [--dtype DTYPE]\n                                  [--device-map DEVICE_MAP]\n                                  [--no-trust-remote-code] [--no-4bit]\n                                  [--bnb-4bit-compute-dtype BNB_4BIT_COMPUTE_DTYPE]\n                                  [--temperature TEMPERATURE] [--top-p TOP_P]\n                                  [--max-new-tokens MAX_NEW_TOKENS] [--no-cot]\n                                  [--approachability]\n                                  [--app-group-cols APP_GROUP_COLS]\n                                  [--app-bins APP_BINS] [--app-eps APP_EPS]\n                                  [--app-time-col APP_TIME_COL]\n                                  [--app-curve-every APP_CURVE_EVERY]\n                                  [--app-topk APP_TOPK]\n                                  [--app-clip-eps APP_CLIP_EPS]\n                                  [--repair-at-resolution]\n                                  [--repair-group-cols REPAIR_GROUP_COLS]\n                                  [--repair-bins REPAIR_BINS]\n                                  [--repair-prior-strength REPAIR_PRIOR_STRENGTH]\n                                  [--repair-forecast-time-col REPAIR_FORECAST_TIME_COL]\n                                  [--repair-event-time-col REPAIR_EVENT_TIME_COL]\n                                  [--repair-clip-eps REPAIR_CLIP_EPS]\nforecastbench pm_rlvr_eval: error: the following arguments are required: --adapter-path\n", "ts": "2025-12-27T21:11:22Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 0, "id": "pm_hybrid_train_fixed_v1", "log": "remote_logs/pm_hybrid_train_fixed_v1.log", "pid": 899494, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 1000 rows from /root/polymarket_data/derived/gamma_yesno_ready.parquet\nTrain: 800, Test: 200\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.81it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.74it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.72it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.72it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.71it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.71it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.71it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.05it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.84it/s]\n", "ts": "2025-12-27T23:37:15Z"}
{"error": "Launch failed for synth_market_factor_d32_m16 (code=255): Connection reset by 95.133.252.72 port 22", "event": "launch_failed", "gpu": 1, "id": "synth_market_factor_d32_m16", "ts": "2025-12-28T04:37:46Z"}
{"done_ts": "2025-12-28T04:37:51Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "synth_market_chain_d32_m16", "log": "remote_logs/synth_market_chain_d32_m16.log", "pid": 1042502, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4564, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3191, in cmd_synth_market\n    results = run_synth_market_benchmark(spec)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 317, in run_synth_market_benchmark\n    P_pred_ar = ar_predictor_oracle(X_test, P_test, L=L)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 253, in ar_predictor_oracle\n    from sklearn.linear_model import LogisticRegression\nModuleNotFoundError: No module named 'sklearn'\nRunning synthetic market benchmark: chain\n  d=32, m=16, n_train=20000, n_test=5000\n", "ts": "2025-12-28T04:43:18Z"}
{"done_ts": "2025-12-28T04:48:11Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "synth_market_frechet_d32_m16", "log": "remote_logs/synth_market_frechet_d32_m16.log", "pid": 1043601, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4564, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3191, in cmd_synth_market\n    results = run_synth_market_benchmark(spec)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 317, in run_synth_market_benchmark\n    P_pred_ar = ar_predictor_oracle(X_test, P_test, L=L)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 253, in ar_predictor_oracle\n    from sklearn.linear_model import LogisticRegression\nModuleNotFoundError: No module named 'sklearn'\nRunning synthetic market benchmark: frechet\n  d=32, m=16, n_train=20000, n_test=5000\n", "ts": "2025-12-28T04:48:37Z"}
{"done_ts": "2025-12-28T04:48:56Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "synth_market_factor_d32_m24", "log": "remote_logs/synth_market_factor_d32_m24.log", "pid": 1044540, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4564, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3191, in cmd_synth_market\n    results = run_synth_market_benchmark(spec)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 317, in run_synth_market_benchmark\n    P_pred_ar = ar_predictor_oracle(X_test, P_test, L=L)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 253, in ar_predictor_oracle\n    from sklearn.linear_model import LogisticRegression\nModuleNotFoundError: No module named 'sklearn'\nRunning synthetic market benchmark: factor\n  d=32, m=24, n_train=20000, n_test=5000\n", "ts": "2025-12-28T04:50:13Z"}
{"done_ts": "2025-12-28T04:49:29Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "synth_market_chain_d32_m24", "log": "remote_logs/synth_market_chain_d32_m24.log", "pid": 1044690, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4564, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3191, in cmd_synth_market\n    results = run_synth_market_benchmark(spec)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 317, in run_synth_market_benchmark\n    P_pred_ar = ar_predictor_oracle(X_test, P_test, L=L)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 253, in ar_predictor_oracle\n    from sklearn.linear_model import LogisticRegression\nModuleNotFoundError: No module named 'sklearn'\nRunning synthetic market benchmark: chain\n  d=32, m=24, n_train=20000, n_test=5000\n", "ts": "2025-12-28T04:50:25Z"}
{"done_ts": "2025-12-28T04:50:42Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "synth_market_frechet_d32_m24", "log": "remote_logs/synth_market_frechet_d32_m24.log", "pid": 1046983, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4564, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3191, in cmd_synth_market\n    results = run_synth_market_benchmark(spec)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 317, in run_synth_market_benchmark\n    P_pred_ar = ar_predictor_oracle(X_test, P_test, L=L)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 253, in ar_predictor_oracle\n    from sklearn.linear_model import LogisticRegression\nModuleNotFoundError: No module named 'sklearn'\nRunning synthetic market benchmark: frechet\n  d=32, m=24, n_train=20000, n_test=5000\n", "ts": "2025-12-28T04:52:03Z"}
{"done_ts": "2025-12-28T04:50:50Z", "event": "failed", "exit_code": 128, "gpu": 1, "id": "git_pull_and_install", "log": "remote_logs/git_pull_and_install.log", "pid": 1047283, "tail": "fatal: not a git repository (or any of the parent directories): .git\n", "ts": "2025-12-28T04:52:17Z"}
{"done_ts": "2025-12-28T06:00:03Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "synth_market_independent_d32_m8", "log": "remote_logs/synth_market_independent_d32_m8.log", "pid": 1072179, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4564, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3191, in cmd_synth_market\n    results = run_synth_market_benchmark(spec)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 317, in run_synth_market_benchmark\n    P_pred_ar = ar_predictor_oracle(X_test, P_test, L=L)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 253, in ar_predictor_oracle\n    from sklearn.linear_model import LogisticRegression\nModuleNotFoundError: No module named 'sklearn'\nRunning synthetic market benchmark: independent\n  d=32, m=8, n_train=20000, n_test=5000\n", "ts": "2025-12-28T06:01:33Z"}
{"done_ts": "2025-12-28T06:03:39Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "synth_market_factor_d32_m8", "log": "remote_logs/synth_market_factor_d32_m8.log", "pid": 1074069, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4564, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3191, in cmd_synth_market\n    results = run_synth_market_benchmark(spec)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 317, in run_synth_market_benchmark\n    P_pred_ar = ar_predictor_oracle(X_test, P_test, L=L)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 253, in ar_predictor_oracle\n    from sklearn.linear_model import LogisticRegression\nModuleNotFoundError: No module named 'sklearn'\nRunning synthetic market benchmark: factor\n  d=32, m=8, n_train=20000, n_test=5000\n", "ts": "2025-12-28T06:05:15Z"}
{"done_ts": "2025-12-28T06:05:38Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "synth_market_chain_d32_m8", "log": "remote_logs/synth_market_chain_d32_m8.log", "pid": 1075298, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4564, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3191, in cmd_synth_market\n    results = run_synth_market_benchmark(spec)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 317, in run_synth_market_benchmark\n    P_pred_ar = ar_predictor_oracle(X_test, P_test, L=L)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 253, in ar_predictor_oracle\n    from sklearn.linear_model import LogisticRegression\nModuleNotFoundError: No module named 'sklearn'\nRunning synthetic market benchmark: chain\n  d=32, m=8, n_train=20000, n_test=5000\n", "ts": "2025-12-28T06:07:12Z"}
{"done_ts": "2025-12-28T06:07:36Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "synth_market_frechet_d32_m8", "log": "remote_logs/synth_market_frechet_d32_m8.log", "pid": 1076927, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4564, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3191, in cmd_synth_market\n    results = run_synth_market_benchmark(spec)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 317, in run_synth_market_benchmark\n    P_pred_ar = ar_predictor_oracle(X_test, P_test, L=L)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 253, in ar_predictor_oracle\n    from sklearn.linear_model import LogisticRegression\nModuleNotFoundError: No module named 'sklearn'\nRunning synthetic market benchmark: frechet\n  d=32, m=8, n_train=20000, n_test=5000\n", "ts": "2025-12-28T06:09:09Z"}
{"done_ts": "2025-12-28T06:09:34Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "synth_market_hierarchical_d32_m8", "log": "remote_logs/synth_market_hierarchical_d32_m8.log", "pid": 1078777, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4564, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3191, in cmd_synth_market\n    results = run_synth_market_benchmark(spec)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 317, in run_synth_market_benchmark\n    P_pred_ar = ar_predictor_oracle(X_test, P_test, L=L)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 253, in ar_predictor_oracle\n    from sklearn.linear_model import LogisticRegression\nModuleNotFoundError: No module named 'sklearn'\nRunning synthetic market benchmark: hierarchical\n  d=32, m=8, n_train=20000, n_test=5000\n", "ts": "2025-12-28T06:11:12Z"}
{"done_ts": "2025-12-28T08:26:00Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_difftrain_fixed20k_gpu0", "log": "remote_logs/pm_difftrain_fixed20k_gpu0.log", "pid": 1120038, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4564, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 200/6000  loss=1.003795  lr=2.00e-04\n[diffusion] step 400/6000  loss=0.513285  lr=1.99e-04\n[diffusion] step 600/6000  loss=0.438038  lr=1.96e-04\n[diffusion] step 800/6000  loss=0.400846  lr=1.93e-04\n[diffusion] step 1000/6000  loss=0.383384  lr=1.89e-04\n[diffusion] step 1200/6000  loss=0.366477  lr=1.83e-04\n[diffusion] step 1400/6000  loss=0.356869  lr=1.77e-04\n[diffusion] step 1600/6000  loss=0.350992  lr=1.70e-04\n[diffusion] step 1800/6000  loss=0.346905  lr=1.62e-04\n[diffusion] step 2000/6000  loss=0.331423  lr=1.53e-04\n[diffusion] step 2200/6000  loss=0.319515  lr=1.44e-04\n[diffusion] step 2400/6000  loss=0.402508  lr=1.34e-04\n[diffusion] step 2600/6000  loss=0.366762  lr=1.24e-04\n[diffusion] step 2800/6000  loss=0.346281  lr=1.13e-04\n[diffusion] step 3000/6000  loss=0.329944  lr=1.03e-04\n[diffusion] step 3200/6000  loss=0.312872  lr=9.20e-05\n[diffusion] step 3400/6000  loss=0.308512  lr=8.15e-05\n[diffusion] step 3600/6000  loss=0.268662  lr=7.11e-05\n[diffusion] step 3800/6000  loss=0.208575  lr=6.11e-05\n[diffusion] step 4000/6000  loss=0.158910  lr=5.15e-05\n[diffusion] step 4200/6000  loss=0.149376  lr=4.25e-05\n[diffusion] step 4400/6000  loss=0.130322  lr=3.41e-05\n[diffusion] step 4600/6000  loss=0.118807  lr=2.65e-05\n[diffusion] step 4800/6000  loss=0.102884  lr=1.97e-05\n[diffusion] step 5000/6000  loss=0.096743  lr=1.38e-05\n[diffusion] step 5200/6000  loss=0.091115  lr=8.94e-06\n[diffusion] step 5400/6000  loss=0.086331  lr=5.06e-06\n[diffusion] step 5600/6000  loss=0.079423  lr=2.26e-06\n[diffusion] step 5800/6000  loss=0.081541  lr=5.67e-07\n[diffusion] step 6000/6000  loss=0.077783  lr=0.00e+00\n", "ts": "2025-12-28T08:26:57Z"}
{"done_ts": "2025-12-28T08:31:28Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "pm_difftrain_huge_h768d8_gpu1", "log": "remote_logs/pm_difftrain_huge_h768d8_gpu1.log", "pid": 1128157, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n", "ts": "2025-12-28T08:34:01Z"}
{"done_ts": "2025-12-28T08:36:46Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "pm_difftrain_T32_s32_gpu1", "log": "remote_logs/pm_difftrain_T32_s32_gpu1.log", "pid": 1131775, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4574, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 200/6000  loss=1.024814  lr=2.00e-04\n[diffusion] step 400/6000  loss=0.824708  lr=1.99e-04\n[diffusion] step 600/6000  loss=0.464837  lr=1.96e-04\n[diffusion] step 800/6000  loss=0.422435  lr=1.93e-04\n[diffusion] step 1000/6000  loss=0.401344  lr=1.89e-04\n[diffusion] step 1200/6000  loss=0.385084  lr=1.83e-04\n[diffusion] step 1400/6000  loss=0.375194  lr=1.77e-04\n[diffusion] step 1600/6000  loss=0.369531  lr=1.70e-04\n[diffusion] step 1800/6000  loss=0.361887  lr=1.62e-04\n[diffusion] step 2000/6000  loss=0.347078  lr=1.53e-04\n[diffusion] step 2200/6000  loss=0.337248  lr=1.44e-04\n[diffusion] step 2400/6000  loss=0.342291  lr=1.34e-04\n[diffusion] step 2600/6000  loss=0.335704  lr=1.24e-04\n[diffusion] step 2800/6000  loss=0.342933  lr=1.13e-04\n[diffusion] step 3000/6000  loss=0.398123  lr=1.03e-04\n[diffusion] step 3200/6000  loss=0.345586  lr=9.20e-05\n[diffusion] step 3400/6000  loss=0.342502  lr=8.15e-05\n[diffusion] step 3600/6000  loss=0.326789  lr=7.11e-05\n[diffusion] step 3800/6000  loss=0.320904  lr=6.11e-05\n[diffusion] step 4000/6000  loss=0.316267  lr=5.15e-05\n[diffusion] step 4200/6000  loss=0.312770  lr=4.25e-05\n[diffusion] step 4400/6000  loss=0.309309  lr=3.41e-05\n[diffusion] step 4600/6000  loss=0.324391  lr=2.65e-05\n[diffusion] step 4800/6000  loss=0.308301  lr=1.97e-05\n[diffusion] step 5000/6000  loss=0.296700  lr=1.38e-05\n[diffusion] step 5200/6000  loss=0.292027  lr=8.94e-06\n[diffusion] step 5400/6000  loss=0.286857  lr=5.06e-06\n[diffusion] step 5600/6000  loss=0.273518  lr=2.26e-06\n[diffusion] step 5800/6000  loss=0.282911  lr=5.67e-07\n[diffusion] step 6000/6000  loss=0.278705  lr=0.00e+00\n", "ts": "2025-12-28T08:37:41Z"}
{"done_ts": "2025-12-28T08:36:20Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "synth_market_chain_d64_m16_gpu1", "log": "remote_logs/synth_market_chain_d64_m16_gpu1.log", "pid": 1132159, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4574, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3191, in cmd_synth_market\n    results = run_synth_market_benchmark(spec)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 317, in run_synth_market_benchmark\n    P_pred_ar = ar_predictor_oracle(X_test, P_test, L=L)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/synth_market_compare.py\", line 266, in ar_predictor_oracle\n    model.fit(X_limited, y_binary)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1335, in fit\n    raise ValueError(\nValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(0)\nRunning synthetic market benchmark: chain\n  d=64, m=16, n_train=50000, n_test=10000\n", "ts": "2025-12-28T08:37:56Z"}
{"done_ts": "2025-12-28T08:39:38Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_difftrain_fixed20k_qwen_gpu0", "log": "remote_logs/pm_difftrain_fixed20k_qwen_gpu0.log", "pid": 1124791, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:04,  1.75it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.67it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:03,  1.65it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.64it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:03<00:01,  1.63it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.63it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.63it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.85it/s]\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4564, in main\n    from backtest.cli import add_backtest_parser\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 200/6000  loss=1.052074  lr=2.00e-04\n[diffusion] step 400/6000  loss=0.987301  lr=1.99e-04\n[diffusion] step 600/6000  loss=0.551806  lr=1.96e-04\n[diffusion] step 800/6000  loss=0.411192  lr=1.93e-04\n[diffusion] step 1000/6000  loss=0.380530  lr=1.89e-04\n[diffusion] step 1200/6000  loss=0.365565  lr=1.83e-04\n[diffusion] step 1400/6000  loss=0.354510  lr=1.77e-04\n[diffusion] step 1600/6000  loss=0.350451  lr=1.70e-04\n[diffusion] step 1800/6000  loss=0.343026  lr=1.62e-04\n[diffusion] step 2000/6000  loss=0.331884  lr=1.53e-04\n[diffusion] step 2200/6000  loss=0.318399  lr=1.44e-04\n[diffusion] step 2400/6000  loss=0.444050  lr=1.34e-04\n[diffusion] step 2600/6000  loss=0.426754  lr=1.24e-04\n[diffusion] step 2800/6000  loss=0.399198  lr=1.13e-04\n[diffusion] step 3000/6000  loss=0.372793  lr=1.03e-04\n[diffusion] step 3200/6000  loss=0.353424  lr=9.20e-05\n[diffusion] step 3400/6000  loss=0.366813  lr=8.15e-05\n[diffusion] step 3600/6000  loss=0.311891  lr=7.11e-05\n[diffusion] step 3800/6000  loss=0.315274  lr=6.11e-05\n[diffusion] step 4000/6000  loss=0.320257  lr=5.15e-05\n[diffusion] step 4200/6000  loss=0.320393  lr=4.25e-05\n[diffusion] step 4400/6000  loss=0.296971  lr=3.41e-05\n[diffusion] step 4600/6000  loss=0.296668  lr=2.65e-05\n[diffusion] step 4800/6000  loss=0.288410  lr=1.97e-05\n[diffusion] step 5000/6000  loss=0.286635  lr=1.38e-05\n[diffusion] step 5200/6000  loss=0.279597  lr=8.94e-06\n[diffusion] step 5400/6000  loss=0.278349  lr=5.06e-06\n[diffusion] step 5600/6000  loss=0.267485  lr=2.26e-06\n[diffusion] step 5800/6000  loss=0.275463  lr=5.67e-07\n[diffusion] step 6000/6000  loss=0.271995  lr=0.00e+00\n", "ts": "2025-12-28T08:39:47Z"}
{"done_ts": "2025-12-28T08:41:53Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_difftrain_big_h512d6_gpu0", "log": "remote_logs/pm_difftrain_big_h512d6_gpu0.log", "pid": 1138001, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4576, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 200/8000  loss=1.044393  lr=1.00e-04\n[diffusion] step 400/8000  loss=0.867417  lr=9.96e-05\n[diffusion] step 600/8000  loss=0.476071  lr=9.90e-05\n[diffusion] step 800/8000  loss=0.411792  lr=9.81e-05\n[diffusion] step 1000/8000  loss=0.382987  lr=9.68e-05\n[diffusion] step 1200/8000  loss=0.361923  lr=9.53e-05\n[diffusion] step 1400/8000  loss=0.369596  lr=9.35e-05\n[diffusion] step 1600/8000  loss=0.399939  lr=9.14e-05\n[diffusion] step 1800/8000  loss=0.325028  lr=8.90e-05\n[diffusion] step 2000/8000  loss=0.286431  lr=8.64e-05\n[diffusion] step 2200/8000  loss=0.233776  lr=8.36e-05\n[diffusion] step 2400/8000  loss=0.206940  lr=8.05e-05\n[diffusion] step 2600/8000  loss=0.195054  lr=7.73e-05\n[diffusion] step 2800/8000  loss=0.155510  lr=7.38e-05\n[diffusion] step 3000/8000  loss=0.167238  lr=7.03e-05\n[diffusion] step 3200/8000  loss=0.201297  lr=6.66e-05\n[diffusion] step 3400/8000  loss=0.165484  lr=6.28e-05\n[diffusion] step 3600/8000  loss=0.139935  lr=5.89e-05\n[diffusion] step 3800/8000  loss=0.132902  lr=5.50e-05\n[diffusion] step 4000/8000  loss=0.130627  lr=5.10e-05\n[diffusion] step 4200/8000  loss=0.120877  lr=4.70e-05\n[diffusion] step 4400/8000  loss=0.094252  lr=4.31e-05\n[diffusion] step 4600/8000  loss=0.094457  lr=3.92e-05\n[diffusion] step 4800/8000  loss=0.098367  lr=3.53e-05\n[diffusion] step 5000/8000  loss=0.079961  lr=3.16e-05\n[diffusion] step 5200/8000  loss=0.075528  lr=2.79e-05\n[diffusion] step 5400/8000  loss=0.072075  lr=2.44e-05\n[diffusion] step 5600/8000  loss=0.066616  lr=2.11e-05\n[diffusion] step 5800/8000  loss=0.065065  lr=1.79e-05\n[diffusion] step 6000/8000  loss=0.054730  lr=1.50e-05\n[diffusion] step 6200/8000  loss=0.051480  lr=1.23e-05\n[diffusion] step 6400/8000  loss=0.044467  lr=9.78e-06\n[diffusion] step 6600/8000  loss=0.042858  lr=7.55e-06\n[diffusion] step 6800/8000  loss=0.038685  lr=5.59e-06\n[diffusion] step 7000/8000  loss=0.039446  lr=3.90e-06\n[diffusion] step 7200/8000  loss=0.031883  lr=2.51e-06\n[diffusion] step 7400/8000  loss=0.029690  lr=1.42e-06\n[diffusion] step 7600/8000  loss=0.028372  lr=6.31e-07\n[diffusion] step 7800/8000  loss=0.028149  lr=1.58e-07\n[diffusion] step 8000/8000  loss=0.026918  lr=0.00e+00\n", "ts": "2025-12-28T08:42:30Z"}
{"done_ts": "2025-12-28T08:45:18Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_difftrain_T128_s128_gpu0", "log": "remote_logs/pm_difftrain_T128_s128_gpu0.log", "pid": 1141809, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4576, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 200/6000  loss=0.906723  lr=2.00e-04\n[diffusion] step 400/6000  loss=0.577452  lr=1.99e-04\n[diffusion] step 600/6000  loss=0.427885  lr=1.96e-04\n[diffusion] step 800/6000  loss=0.394005  lr=1.93e-04\n[diffusion] step 1000/6000  loss=0.381239  lr=1.89e-04\n[diffusion] step 1200/6000  loss=0.357648  lr=1.83e-04\n[diffusion] step 1400/6000  loss=0.352236  lr=1.77e-04\n[diffusion] step 1600/6000  loss=0.283952  lr=1.70e-04\n[diffusion] step 1800/6000  loss=0.262172  lr=1.62e-04\n[diffusion] step 2000/6000  loss=0.175307  lr=1.53e-04\n[diffusion] step 2200/6000  loss=0.172520  lr=1.44e-04\n[diffusion] step 2400/6000  loss=0.160952  lr=1.34e-04\n[diffusion] step 2600/6000  loss=0.141198  lr=1.24e-04\n[diffusion] step 2800/6000  loss=0.140739  lr=1.13e-04\n[diffusion] step 3000/6000  loss=0.120301  lr=1.03e-04\n[diffusion] step 3200/6000  loss=0.118383  lr=9.20e-05\n[diffusion] step 3400/6000  loss=0.095029  lr=8.15e-05\n[diffusion] step 3600/6000  loss=0.084907  lr=7.11e-05\n[diffusion] step 3800/6000  loss=0.077809  lr=6.11e-05\n[diffusion] step 4000/6000  loss=0.074589  lr=5.15e-05\n[diffusion] step 4200/6000  loss=0.064395  lr=4.25e-05\n[diffusion] step 4400/6000  loss=0.061861  lr=3.41e-05\n[diffusion] step 4600/6000  loss=0.054262  lr=2.65e-05\n[diffusion] step 4800/6000  loss=0.051357  lr=1.97e-05\n[diffusion] step 5000/6000  loss=0.046088  lr=1.38e-05\n[diffusion] step 5200/6000  loss=0.042439  lr=8.94e-06\n[diffusion] step 5400/6000  loss=0.039174  lr=5.06e-06\n[diffusion] step 5600/6000  loss=0.036551  lr=2.26e-06\n[diffusion] step 5800/6000  loss=0.036882  lr=5.67e-07\n[diffusion] step 6000/6000  loss=0.035236  lr=0.00e+00\n", "ts": "2025-12-28T08:45:29Z"}
{"done_ts": "2025-12-28T08:45:01Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "pm_difftrain_lr5e5_gpu1", "log": "remote_logs/pm_difftrain_lr5e5_gpu1.log", "pid": 1142270, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4576, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 200/8000  loss=1.024834  lr=5.00e-05\n[diffusion] step 400/8000  loss=0.612420  lr=4.98e-05\n[diffusion] step 600/8000  loss=0.471279  lr=4.95e-05\n[diffusion] step 800/8000  loss=0.404660  lr=4.90e-05\n[diffusion] step 1000/8000  loss=0.380279  lr=4.84e-05\n[diffusion] step 1200/8000  loss=0.369697  lr=4.76e-05\n[diffusion] step 1400/8000  loss=0.364029  lr=4.67e-05\n[diffusion] step 1600/8000  loss=0.358364  lr=4.57e-05\n[diffusion] step 1800/8000  loss=0.356500  lr=4.45e-05\n[diffusion] step 2000/8000  loss=0.337714  lr=4.32e-05\n[diffusion] step 2200/8000  loss=0.353088  lr=4.18e-05\n[diffusion] step 2400/8000  loss=0.339913  lr=4.03e-05\n[diffusion] step 2600/8000  loss=0.331646  lr=3.86e-05\n[diffusion] step 2800/8000  loss=0.349988  lr=3.69e-05\n[diffusion] step 3000/8000  loss=0.329039  lr=3.51e-05\n[diffusion] step 3200/8000  loss=0.332961  lr=3.33e-05\n[diffusion] step 3400/8000  loss=0.338267  lr=3.14e-05\n[diffusion] step 3600/8000  loss=0.320955  lr=2.94e-05\n[diffusion] step 3800/8000  loss=0.317784  lr=2.75e-05\n[diffusion] step 4000/8000  loss=0.325946  lr=2.55e-05\n[diffusion] step 4200/8000  loss=0.308875  lr=2.35e-05\n[diffusion] step 4400/8000  loss=0.321565  lr=2.15e-05\n[diffusion] step 4600/8000  loss=0.309299  lr=1.96e-05\n[diffusion] step 4800/8000  loss=0.312858  lr=1.77e-05\n[diffusion] step 5000/8000  loss=0.307124  lr=1.58e-05\n[diffusion] step 5200/8000  loss=0.308854  lr=1.40e-05\n[diffusion] step 5400/8000  loss=0.299146  lr=1.22e-05\n[diffusion] step 5600/8000  loss=0.289941  lr=1.05e-05\n[diffusion] step 5800/8000  loss=0.297135  lr=8.97e-06\n[diffusion] step 6000/8000  loss=0.290802  lr=7.50e-06\n[diffusion] step 6200/8000  loss=0.288509  lr=6.14e-06\n[diffusion] step 6400/8000  loss=0.283782  lr=4.89e-06\n[diffusion] step 6600/8000  loss=0.283554  lr=3.78e-06\n[diffusion] step 6800/8000  loss=0.284113  lr=2.79e-06\n[diffusion] step 7000/8000  loss=0.280960  lr=1.95e-06\n[diffusion] step 7200/8000  loss=0.277946  lr=1.25e-06\n[diffusion] step 7400/8000  loss=0.282307  lr=7.08e-07\n[diffusion] step 7600/8000  loss=0.272482  lr=3.16e-07\n[diffusion] step 7800/8000  loss=0.275545  lr=7.90e-08\n[diffusion] step 8000/8000  loss=0.272669  lr=0.00e+00\n", "ts": "2025-12-28T08:45:43Z"}
{"done_ts": "2025-12-28T08:44:57Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "pm_difftrain_seed42_gpu1", "log": "remote_logs/pm_difftrain_seed42_gpu1.log", "pid": 1142689, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4576, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 200/6000  loss=1.038292  lr=2.00e-04\n[diffusion] step 400/6000  loss=0.539025  lr=1.99e-04\n[diffusion] step 600/6000  loss=0.417028  lr=1.96e-04\n[diffusion] step 800/6000  loss=0.398285  lr=1.93e-04\n[diffusion] step 1000/6000  loss=0.371268  lr=1.89e-04\n[diffusion] step 1200/6000  loss=0.360092  lr=1.83e-04\n[diffusion] step 1400/6000  loss=0.353543  lr=1.77e-04\n[diffusion] step 1600/6000  loss=0.343064  lr=1.70e-04\n[diffusion] step 1800/6000  loss=0.331445  lr=1.62e-04\n[diffusion] step 2000/6000  loss=0.321263  lr=1.53e-04\n[diffusion] step 2200/6000  loss=0.315189  lr=1.44e-04\n[diffusion] step 2400/6000  loss=0.317069  lr=1.34e-04\n[diffusion] step 2600/6000  loss=0.310094  lr=1.24e-04\n[diffusion] step 2800/6000  loss=0.248410  lr=1.13e-04\n[diffusion] step 3000/6000  loss=0.210240  lr=1.03e-04\n[diffusion] step 3200/6000  loss=0.190674  lr=9.20e-05\n[diffusion] step 3400/6000  loss=0.176064  lr=8.15e-05\n[diffusion] step 3600/6000  loss=0.153885  lr=7.11e-05\n[diffusion] step 3800/6000  loss=0.144324  lr=6.11e-05\n[diffusion] step 4000/6000  loss=0.109999  lr=5.15e-05\n[diffusion] step 4200/6000  loss=0.120764  lr=4.25e-05\n[diffusion] step 4400/6000  loss=0.099240  lr=3.41e-05\n[diffusion] step 4600/6000  loss=0.094689  lr=2.65e-05\n[diffusion] step 4800/6000  loss=0.089312  lr=1.97e-05\n[diffusion] step 5000/6000  loss=0.074831  lr=1.38e-05\n[diffusion] step 5200/6000  loss=0.069193  lr=8.94e-06\n[diffusion] step 5400/6000  loss=0.065796  lr=5.06e-06\n[diffusion] step 5600/6000  loss=0.061640  lr=2.26e-06\n[diffusion] step 5800/6000  loss=0.060357  lr=5.67e-07\n[diffusion] step 6000/6000  loss=0.058832  lr=0.00e+00\n", "ts": "2025-12-28T08:45:56Z"}
{"done_ts": "2025-12-28T08:52:26Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_difftrain_lr1e3_gpu0", "log": "remote_logs/pm_difftrain_lr1e3_gpu0.log", "pid": 1153714, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4576, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 200/6000  loss=1.075306  lr=9.99e-04\n[diffusion] step 400/6000  loss=1.002161  lr=9.94e-04\n[diffusion] step 600/6000  loss=0.642053  lr=9.82e-04\n[diffusion] step 800/6000  loss=0.513593  lr=9.66e-04\n[diffusion] step 1000/6000  loss=0.492314  lr=9.44e-04\n[diffusion] step 1200/6000  loss=0.389139  lr=9.17e-04\n[diffusion] step 1400/6000  loss=0.370342  lr=8.85e-04\n[diffusion] step 1600/6000  loss=0.363993  lr=8.49e-04\n[diffusion] step 1800/6000  loss=0.354221  lr=8.09e-04\n[diffusion] step 2000/6000  loss=0.346117  lr=7.65e-04\n[diffusion] step 2200/6000  loss=0.346852  lr=7.19e-04\n[diffusion] step 2400/6000  loss=0.379645  lr=6.70e-04\n[diffusion] step 2600/6000  loss=0.366997  lr=6.19e-04\n[diffusion] step 2800/6000  loss=0.356144  lr=5.66e-04\n[diffusion] step 3000/6000  loss=0.344240  lr=5.13e-04\n[diffusion] step 3200/6000  loss=0.314380  lr=4.60e-04\n[diffusion] step 3400/6000  loss=0.323441  lr=4.07e-04\n[diffusion] step 3600/6000  loss=0.320277  lr=3.56e-04\n[diffusion] step 3800/6000  loss=0.307830  lr=3.06e-04\n[diffusion] step 4000/6000  loss=0.305012  lr=2.58e-04\n[diffusion] step 4200/6000  loss=0.282674  lr=2.13e-04\n[diffusion] step 4400/6000  loss=0.256964  lr=1.71e-04\n[diffusion] step 4600/6000  loss=0.233169  lr=1.33e-04\n[diffusion] step 4800/6000  loss=0.199554  lr=9.86e-05\n[diffusion] step 5000/6000  loss=0.188445  lr=6.92e-05\n[diffusion] step 5200/6000  loss=0.187194  lr=4.47e-05\n[diffusion] step 5400/6000  loss=0.174500  lr=2.53e-05\n[diffusion] step 5600/6000  loss=0.164492  lr=1.13e-05\n[diffusion] step 5800/6000  loss=0.169941  lr=2.83e-06\n[diffusion] step 6000/6000  loss=0.166431  lr=0.00e+00\n", "ts": "2025-12-28T08:53:28Z"}
{"done_ts": "2025-12-28T08:55:18Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_difftrain_long15k_gpu0", "log": "remote_logs/pm_difftrain_long15k_gpu0.log", "pid": 1156378, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4576, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 500/15000  loss=0.692172  lr=2.00e-04\n[diffusion] step 1000/15000  loss=0.391228  lr=1.98e-04\n[diffusion] step 1500/15000  loss=0.359029  lr=1.96e-04\n[diffusion] step 2000/15000  loss=0.343471  lr=1.92e-04\n[diffusion] step 2500/15000  loss=0.329516  lr=1.87e-04\n[diffusion] step 3000/15000  loss=0.325392  lr=1.82e-04\n[diffusion] step 3500/15000  loss=0.214629  lr=1.75e-04\n[diffusion] step 4000/15000  loss=0.185005  lr=1.68e-04\n[diffusion] step 4500/15000  loss=0.149736  lr=1.60e-04\n[diffusion] step 5000/15000  loss=0.129050  lr=1.51e-04\n[diffusion] step 5500/15000  loss=0.127463  lr=1.42e-04\n[diffusion] step 6000/15000  loss=0.125263  lr=1.32e-04\n[diffusion] step 6500/15000  loss=0.102422  lr=1.22e-04\n[diffusion] step 7000/15000  loss=0.091001  lr=1.12e-04\n[diffusion] step 7500/15000  loss=0.088802  lr=1.01e-04\n[diffusion] step 8000/15000  loss=0.066055  lr=9.05e-05\n[diffusion] step 8500/15000  loss=0.061109  lr=8.01e-05\n[diffusion] step 9000/15000  loss=0.070376  lr=6.99e-05\n[diffusion] step 9500/15000  loss=0.052515  lr=6.00e-05\n[diffusion] step 10000/15000  loss=0.054259  lr=5.06e-05\n[diffusion] step 10500/15000  loss=0.039809  lr=4.17e-05\n[diffusion] step 11000/15000  loss=0.038652  lr=3.35e-05\n[diffusion] step 11500/15000  loss=0.031865  lr=2.60e-05\n[diffusion] step 12000/15000  loss=0.026452  lr=1.93e-05\n[diffusion] step 12500/15000  loss=0.023568  lr=1.36e-05\n[diffusion] step 13000/15000  loss=0.021508  lr=8.76e-06\n[diffusion] step 13500/15000  loss=0.017823  lr=4.96e-06\n[diffusion] step 14000/15000  loss=0.015410  lr=2.21e-06\n[diffusion] step 14500/15000  loss=0.013653  lr=5.55e-07\n[diffusion] step 15000/15000  loss=0.013454  lr=0.00e+00\n", "ts": "2025-12-28T09:10:35Z"}
{"done_ts": "2025-12-28T08:54:55Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_difftrain_seed123_gpu0", "log": "remote_logs/pm_difftrain_seed123_gpu0.log", "pid": 1156763, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4576, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 200/6000  loss=1.026546  lr=2.00e-04\n[diffusion] step 400/6000  loss=0.710812  lr=1.99e-04\n[diffusion] step 600/6000  loss=0.410229  lr=1.96e-04\n[diffusion] step 800/6000  loss=0.384888  lr=1.93e-04\n[diffusion] step 1000/6000  loss=0.368492  lr=1.89e-04\n[diffusion] step 1200/6000  loss=0.356531  lr=1.83e-04\n[diffusion] step 1400/6000  loss=0.356244  lr=1.77e-04\n[diffusion] step 1600/6000  loss=0.340654  lr=1.70e-04\n[diffusion] step 1800/6000  loss=0.327932  lr=1.62e-04\n[diffusion] step 2000/6000  loss=0.335301  lr=1.53e-04\n[diffusion] step 2200/6000  loss=0.354487  lr=1.44e-04\n[diffusion] step 2400/6000  loss=0.352025  lr=1.34e-04\n[diffusion] step 2600/6000  loss=0.340689  lr=1.24e-04\n[diffusion] step 2800/6000  loss=0.331398  lr=1.13e-04\n[diffusion] step 3000/6000  loss=0.319054  lr=1.03e-04\n[diffusion] step 3200/6000  loss=0.310896  lr=9.20e-05\n[diffusion] step 3400/6000  loss=0.274399  lr=8.15e-05\n[diffusion] step 3600/6000  loss=0.223511  lr=7.11e-05\n[diffusion] step 3800/6000  loss=0.175002  lr=6.11e-05\n[diffusion] step 4000/6000  loss=0.158499  lr=5.15e-05\n[diffusion] step 4200/6000  loss=0.137487  lr=4.25e-05\n[diffusion] step 4400/6000  loss=0.113584  lr=3.41e-05\n[diffusion] step 4600/6000  loss=0.115955  lr=2.65e-05\n[diffusion] step 4800/6000  loss=0.092421  lr=1.97e-05\n[diffusion] step 5000/6000  loss=0.085543  lr=1.38e-05\n[diffusion] step 5200/6000  loss=0.084394  lr=8.94e-06\n[diffusion] step 5400/6000  loss=0.075747  lr=5.06e-06\n[diffusion] step 5600/6000  loss=0.072866  lr=2.26e-06\n[diffusion] step 5800/6000  loss=0.069168  lr=5.67e-07\n[diffusion] step 6000/6000  loss=0.069152  lr=0.00e+00\n", "ts": "2025-12-28T09:25:53Z"}
{"done_ts": "2025-12-28T11:12:17Z", "event": "failed", "exit_code": 128, "gpu": 0, "id": "git_pull_h4_v2", "log": "remote_logs/git_pull_h4_v2.log", "pid": 1232528, "tail": "fatal: not a git repository (or any of the parent directories): .git\n", "ts": "2025-12-28T11:14:28Z"}
{"done_ts": "2025-12-28T23:06:11Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "pm_difftrain_clean_data", "log": "remote_logs/pm_difftrain_clean_data.log", "pid": 1447744, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4576, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    metrics = evaluate_polymarket_dataset(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 200/4000  loss=1.011837  lr=2.00e-04\n[diffusion] step 400/4000  loss=0.503150  lr=1.97e-04\n[diffusion] step 600/4000  loss=0.419821  lr=1.92e-04\n[diffusion] step 800/4000  loss=0.384657  lr=1.85e-04\n[diffusion] step 1000/4000  loss=0.370048  lr=1.75e-04\n[diffusion] step 1200/4000  loss=0.351623  lr=1.63e-04\n[diffusion] step 1400/4000  loss=0.342920  lr=1.50e-04\n[diffusion] step 1600/4000  loss=0.338257  lr=1.35e-04\n[diffusion] step 1800/4000  loss=0.395933  lr=1.20e-04\n[diffusion] step 2000/4000  loss=0.408048  lr=1.04e-04\n[diffusion] step 2200/4000  loss=0.371535  lr=8.79e-05\n[diffusion] step 2400/4000  loss=0.360555  lr=7.22e-05\n[diffusion] step 2600/4000  loss=0.315143  lr=5.71e-05\n[diffusion] step 2800/4000  loss=0.321499  lr=4.32e-05\n[diffusion] step 3000/4000  loss=0.298143  lr=3.07e-05\n[diffusion] step 3200/4000  loss=0.289145  lr=2.01e-05\n[diffusion] step 3400/4000  loss=0.285650  lr=1.15e-05\n[diffusion] step 3600/4000  loss=0.282987  lr=5.15e-06\n[diffusion] step 3800/4000  loss=0.271390  lr=1.29e-06\n[diffusion] step 4000/4000  loss=0.267408  lr=0.00e+00\n", "ts": "2025-12-28T23:06:30Z"}
{"done_ts": "2025-12-28T23:53:02Z", "event": "failed", "exit_code": 143, "gpu": 1, "id": "pm_hybrid_clean_v2", "log": "remote_logs/pm_hybrid_clean_v2.log", "pid": 1448065, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 10000 rows from /root/diffusion-markets/experiments/polymarket_backups/pm_suite_derived/gamma_yesno_sample_clob_fixed.parquet\nTrain: 8000, Test: 2000\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.82it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.76it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.74it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.73it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.73it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.72it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.72it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.07it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.85it/s]\nTerminated\n", "ts": "2025-12-28T23:53:30Z"}
{"done_ts": "2025-12-28T23:53:02Z", "event": "failed", "exit_code": 143, "gpu": 0, "id": "pm_hybrid_clean_v1", "log": "remote_logs/pm_hybrid_clean_v1.log", "pid": 1449042, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 5000 rows from /root/diffusion-markets/experiments/polymarket_backups/pm_suite_derived/gamma_yesno_sample_clob_fixed.parquet\nTrain: 4000, Test: 1000\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.82it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.76it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.74it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.73it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02<00:00,  3.41it/s]\nSome parameters are on the meta device because they were offloaded to the cpu.\nTerminated\n", "ts": "2025-12-28T23:53:45Z"}
{"error": "Launch failed for git_pull_hybrid_fix (code=255): Connection closed by 95.133.252.72 port 22", "event": "launch_failed", "gpu": 0, "id": "git_pull_hybrid_fix", "ts": "2025-12-28T23:54:26Z"}
{"done_ts": "2025-12-28T23:54:33Z", "event": "failed", "exit_code": 2, "gpu": 0, "id": "turtel_rlcr_blackwell_suite", "log": "remote_logs/turtel_rlcr_blackwell_suite.log", "pid": 1470789, "tail": "[suite] ==============================================\n[suite] TURTEL/RLCR/BLACKWELL COMPARISON SUITE\n[suite] Start: Sun Dec 28 23:54:25 UTC 2025\n[suite] Log dir: remote_logs/20251228_235425_turtel_rlcr_blackwell\n[suite] ==============================================\n[suite] GPU status:\ntorch 2.9.1+cu128 cuda True\ngpus 1\n  GPU 0: NVIDIA H200\n[suite] ==============================================\n[suite] PHASE 1: SYNTHETIC EXPERIMENTS\n[suite] ==============================================\n[suite] parity --blackwell k=4\nParity benchmark\nmodel                      brier       log       sce       ece  arb(B=1)\n------------------------------------------------------------------------\noracle                  0.089696  0.324248  0.000000  0.001728  0.000000\nconst_0.5               0.250000  0.693147  0.160000  0.000080  0.400000\ndiff_analytic_rho=0.95  0.095258  0.346425  0.005505  0.074577  0.074197\nL_query_oracle(L=4)     0.089696  0.324248  0.000000  0.001728  0.000000\nArtifacts: /root/diffusion-markets/experiments/runs/20251228_235427_turtel_suite_parity_k4\n[suite] parity --blackwell k=6\nParity benchmark\nmodel                      brier       log       sce       ece  arb(B=1)\n------------------------------------------------------------------------\noracle                  0.089696  0.324248  0.000000  0.001652  0.000000\nconst_0.5               0.250000  0.693147  0.160000  0.000820  0.400000\ndiff_analytic_rho=0.95  0.101005  0.365056  0.011228  0.106343  0.105963\nL_query_oracle(L=4)     0.250000  0.693147  0.160000  0.000820  0.400000\nArtifacts: /root/diffusion-markets/experiments/runs/20251228_235428_turtel_suite_parity_k6\n[suite] parity --blackwell k=8\nParity benchmark\nmodel                      brier       log       sce       ece  arb(B=1)\n------------------------------------------------------------------------\noracle                  0.089696  0.324248  0.000000  0.001194  0.000000\nconst_0.5               0.250000  0.693147  0.160000  0.000050  0.400000\ndiff_analytic_rho=0.95  0.107924  0.385183  0.018126  0.135012  0.134632\nL_query_oracle(L=4)     0.250000  0.693147  0.160000  0.000050  0.400000\nArtifacts: /root/diffusion-markets/experiments/runs/20251228_235429_turtel_suite_parity_k8\n[suite] parity --blackwell k=10\nParity benchmark\nmodel                      brier       log       sce       ece  arb(B=1)\n------------------------------------------------------------------------\noracle                  0.089696  0.324248  0.000000  0.000426  0.000000\nconst_0.5               0.250000  0.693147  0.160000  0.000450  0.400000\ndiff_analytic_rho=0.95  0.115580  0.405726  0.025762  0.160885  0.160505\nL_query_oracle(L=4)     0.250000  0.693147  0.160000  0.000450  0.400000\nArtifacts: /root/diffusion-markets/experiments/runs/20251228_235430_turtel_suite_parity_k10\n[suite] parity --blackwell k=12\nParity benchmark\nmodel                      brier       log       sce       ece  arb(B=1)\n------------------------------------------------------------------------\noracle                  0.089696  0.324248  0.000000  0.001726  0.000000\nconst_0.5               0.250000  0.693147  0.160000  0.001590  0.400000\ndiff_analytic_rho=0.95  0.123639  0.426064  0.033803  0.184236  0.183856\nL_query_oracle(L=4)     0.250000  0.693147  0.160000  0.001590  0.400000\nArtifacts: /root/diffusion-markets/experiments/runs/20251228_235431_turtel_suite_parity_k12\n[suite] approachability_suite\nusage: forecastbench [-h]\n                     {parity,groupstress,intrinsic_post,pm_eval,pm_build_polydata,pm_build_subgraph,pm_download_gamma,pm_build_gamma,pm_enrich_clob,pm_download_clob_history,pm_build_horizon_prices,pm_build_criterion_prices,pm_enrich_news_gdelt,pm_difftrain,pm_diff_sample,pm_learnedCt_arb,pm_rlvr_train,pm_rlvr_eval,pm_compare,difftrain,difftrain_simplex,logical_graph,cliff_fog,group_robustness,approachability_suite,swap_regret,turtel_compare,pm_hybrid_train,synth_market,synth_headlines,pm_turtel_headlines,grpo_train,latex}\n                     ...\nforecastbench: error: unrecognized arguments: --degrees 4,6,8,10,12 --n-per-degree 50000 --L 4\n", "ts": "2025-12-28T23:55:22Z"}
{"done_ts": "2025-12-28T23:58:31Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "pm_difftrain_clean_v2", "log": "remote_logs/pm_difftrain_clean_v2.log", "pid": 1470359, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.82it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.77it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.74it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.74it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.74it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.73it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.73it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.96it/s]\nTraceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'topic'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4576, in main\n    p_dts.add_argument(\"--seed\", type=int, default=0)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 1301, in cmd_pm_difftrain\n    sort=str(args.sort),\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in evaluate_polymarket_dataset\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 122, in <dictcomp>\n    out[\"groups\"] = {gc: group_calibration_bias(df, group_col=gc, y_col=y_col, pred_col=pred_col) for gc in group_cols}\n  File \"/root/diffusion-markets/experiments/src/forecastbench/benchmarks/polymarket_eval.py\", line 63, in group_calibration_bias\n    g = df[group_col]\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/frame.py\", line 4113, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3819, in get_loc\n    raise KeyError(key) from err\nKeyError: 'topic'\n[diffusion] step 200/6000  loss=1.048929  lr=9.99e-05\n[diffusion] step 400/6000  loss=0.988892  lr=9.94e-05\n[diffusion] step 600/6000  loss=0.686924  lr=9.82e-05\n[diffusion] step 800/6000  loss=0.430009  lr=9.66e-05\n[diffusion] step 1000/6000  loss=0.393533  lr=9.44e-05\n[diffusion] step 1200/6000  loss=0.370829  lr=9.17e-05\n[diffusion] step 1400/6000  loss=0.362551  lr=8.85e-05\n[diffusion] step 1600/6000  loss=0.350430  lr=8.49e-05\n[diffusion] step 1800/6000  loss=0.344495  lr=8.09e-05\n[diffusion] step 2000/6000  loss=0.324715  lr=7.65e-05\n[diffusion] step 2200/6000  loss=0.326028  lr=7.19e-05\n[diffusion] step 2400/6000  loss=0.314819  lr=6.70e-05\n[diffusion] step 2600/6000  loss=0.301120  lr=6.19e-05\n[diffusion] step 2800/6000  loss=0.297080  lr=5.66e-05\n[diffusion] step 3000/6000  loss=0.371309  lr=5.13e-05\n[diffusion] step 3200/6000  loss=0.256548  lr=4.60e-05\n[diffusion] step 3400/6000  loss=0.236558  lr=4.07e-05\n[diffusion] step 3600/6000  loss=0.177356  lr=3.56e-05\n[diffusion] step 3800/6000  loss=0.136017  lr=3.06e-05\n[diffusion] step 4000/6000  loss=0.117138  lr=2.58e-05\n[diffusion] step 4200/6000  loss=0.111932  lr=2.13e-05\n[diffusion] step 4400/6000  loss=0.107742  lr=1.71e-05\n[diffusion] step 4600/6000  loss=0.090292  lr=1.33e-05\n[diffusion] step 4800/6000  loss=0.078134  lr=9.86e-06\n[diffusion] step 5000/6000  loss=0.077879  lr=6.92e-06\n[diffusion] step 5200/6000  loss=0.066550  lr=4.47e-06\n[diffusion] step 5400/6000  loss=0.066572  lr=2.53e-06\n[diffusion] step 5600/6000  loss=0.058826  lr=1.13e-06\n[diffusion] step 5800/6000  loss=0.058377  lr=2.83e-07\n[diffusion] step 6000/6000  loss=0.057221  lr=0.00e+00\n", "ts": "2025-12-28T23:58:56Z"}
{"done_ts": "2025-12-29T00:12:19Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "ar_rlcr_20k_v1", "log": "remote_logs/ar_rlcr_20k_v1.log", "pid": 1480592, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4893, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3562, in cmd_grpo_train\n    raise ValueError(\"Data must have 'outcome' column\")\nValueError: Data must have 'outcome' column\n", "ts": "2025-12-29T00:13:23Z"}
{"done_ts": "2025-12-29T00:13:58Z", "event": "failed", "exit_code": 143, "gpu": 0, "id": "ar_diffusion_20k_v1", "log": "remote_logs/ar_diffusion_20k_v1.log", "pid": 1480391, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 20000 rows from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\nTrain: 16000, Test: 4000\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.77it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.74it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.72it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.72it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.71it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.71it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.71it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.06it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.84it/s]\nTerminated\n", "ts": "2025-12-29T00:14:33Z"}
{"done_ts": "2025-12-29T00:13:58Z", "event": "failed", "exit_code": 143, "gpu": 0, "id": "ar_diffusion_20k_v1", "log": "remote_logs/ar_diffusion_20k_v1.log", "pid": 1485628, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 20000 rows from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\nTrain: 16000, Test: 4000\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.79it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.74it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.72it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.72it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.72it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.72it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.71it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.06it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.84it/s]\n", "ts": "2025-12-29T00:22:37Z"}
{"done_ts": "2025-12-29T00:23:53Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "ar_rlcr_20k_v1", "log": "remote_logs/ar_rlcr_20k_v1.log", "pid": 1486958, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n[grpo_train] Loaded 20000 samples from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\n[grpo_train] Output directory: runs/ar_rlcr_20k_v1/20251229_002259_ar_rlcr_20k_v1\n[grpo_train] Algorithm: remax\n[grpo_train] Reward mode: rlcr\n[grpo_train] Model: Qwen/Qwen3-14B\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:01<00:13,  1.98s/it]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:04<00:15,  2.56s/it]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:07<00:13,  2.74s/it]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:10<00:11,  2.82s/it]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:13<00:08,  2.87s/it]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:16<00:05,  2.90s/it]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:19<00:02,  2.93s/it]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:20<00:00,  2.16s/it]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:20<00:00,  2.53s/it]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4898, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3636, in cmd_grpo_train\n    results = train_grpo(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/train/grpo.py\", line 1034, in train_grpo\n    rec = trainer.train_step(infos=batch_infos, y=batch_y, q=batch_q)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/train/grpo.py\", line 989, in train_step\n    metrics[\"max_constraint_violation\"] = constraint_info[\"max_violation\"]\nKeyError: 'max_violation'\ntrainable params: 64,225,280 || all params: 14,832,532,480 || trainable%: 0.4330\n", "ts": "2025-12-29T00:24:04Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 1, "id": "ar_rlcr_20k_v1", "log": "remote_logs/ar_rlcr_20k_v1.log", "pid": 1491361, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n[grpo_train] Loaded 20000 samples from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\n[grpo_train] Output directory: runs/ar_rlcr_20k_v1/20251229_002743_ar_rlcr_20k_v1\n[grpo_train] Algorithm: remax\n[grpo_train] Reward mode: rlcr\n[grpo_train] Model: Qwen/Qwen3-14B\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:02<00:14,  2.05s/it]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:05<00:15,  2.64s/it]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:08<00:14,  2.84s/it]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:11<00:11,  2.94s/it]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:14<00:08,  3.00s/it]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:17<00:06,  3.03s/it]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:20<00:03,  3.05s/it]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:21<00:00,  2.24s/it]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:21<00:00,  2.63s/it]\ntrainable params: 64,225,280 || all params: 14,832,532,480 || trainable%: 0.4330\n[grpo] step 10/2000 loss=0.4149 R=0.6319 brier=0.1728 A_std=0.0321 kl=0.0000 fails=0 gibberish=0 time=231.6s\n[grpo] step 20/2000 loss=-1.3833 R=0.4793 brier=0.1951 A_std=0.3141 kl=0.0469 fails=0 gibberish=0 time=463.4s\n[grpo] step 30/2000 loss=-0.7728 R=0.4380 brier=0.2061 A_std=0.2632 kl=0.0469 fails=0 gibberish=0 time=694.5s\n[grpo] step 40/2000 loss=3.0141 R=0.4636 brier=0.2202 A_std=0.1093 kl=-0.1562 fails=0 gibberish=0 time=926.0s\n[grpo] step 50/2000 loss=-1.7757 R=0.3253 brier=0.2759 A_std=0.3510 kl=0.1719 fails=0 gibberish=0 time=1155.7s\n[grpo] step 60/2000 loss=2.3519 R=0.4322 brier=0.1659 A_std=0.1140 kl=0.2031 fails=0 gibberish=0 time=1387.6s\n[grpo] step 70/2000 loss=-0.2663 R=0.4070 brier=0.1905 A_std=0.2829 kl=-0.1484 fails=0 gibberish=0 time=1617.5s\n[grpo] Early stopping at step 75 (no improvement for 20 steps)\n[grpo] Best Brier: 0.0431 at step 55\n[grpo_train] Training complete!\n[grpo_train] Best Brier: 0.0431 at step 55\n[grpo_train] Saved to: runs/ar_rlcr_20k_v1/20251229_002743_ar_rlcr_20k_v1\n", "ts": "2025-12-29T00:57:10Z"}
{"done_ts": "2025-12-29T01:01:35Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "ar_rlcr_20k_highgamma", "log": "remote_logs/ar_rlcr_20k_highgamma.log", "pid": 1508515, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n[grpo_train] Loaded 20000 samples from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\n[grpo_train] Output directory: runs/ar_rlcr_20k_highgamma/20251229_010025_ar_rlcr_20k_highgamma\n[grpo_train] Algorithm: remax\n[grpo_train] Reward mode: rlcr\n[grpo_train] Model: Qwen/Qwen3-14B\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:01<00:13,  1.98s/it]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:04<00:15,  2.59s/it]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:08<00:14,  2.88s/it]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:11<00:11,  2.98s/it]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:14<00:09,  3.04s/it]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:17<00:06,  3.10s/it]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:20<00:03,  3.12s/it]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:21<00:00,  2.29s/it]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:21<00:00,  2.68s/it]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4898, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3636, in cmd_grpo_train\n    results = train_grpo(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/train/grpo.py\", line 1037, in train_grpo\n    rec = trainer.train_step(infos=batch_infos, y=batch_y, q=batch_q)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/train/grpo.py\", line 932, in train_step\n    logp_pol, n_gen = _compute_logps_for_generated(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/train/grpo.py\", line 600, in _compute_logps_for_generated\n    out = model(sequences, attention_mask=attn)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/peft/peft_model.py\", line 1719, in forward\n    return self.base_model(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/peft/tuners/tuners_utils.py\", line 197, in forward\n    return self.model.forward(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/generic.py\", line 918, in wrapper\n    output = func(self, *args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 480, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/generic.py\", line 1072, in wrapper\n    outputs = func(self, *args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 410, in forward\n    hidden_states = decoder_layer(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/modeling_layers.py\", line 94, in __call__\n    return super().__call__(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n    return func(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 275, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 82, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/peft/tuners/lora/bnb.py\", line 518, in forward\n    output = lora_B(lora_A(dropout(x))) * scaling\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/dropout.py\", line 73, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/functional.py\", line 1418, in dropout\n    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 139.80 GiB of which 216.50 MiB is free. Process 1492303 has 28.45 GiB memory in use. Including non-PyTorch memory, this process has 68.88 GiB memory in use. Process 1508722 has 13.86 GiB memory in use. Process 1508956 has 28.38 GiB memory in use. Of the allocated memory 66.62 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\ntrainable params: 64,225,280 || all params: 14,832,532,480 || trainable%: 0.4330\n", "ts": "2025-12-29T01:01:50Z"}
{"done_ts": "2025-12-29T01:01:41Z", "event": "failed", "exit_code": 1, "gpu": 0, "id": "ar_rlcr_20k_nogroup", "log": "remote_logs/ar_rlcr_20k_nogroup.log", "pid": 1508719, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n[grpo_train] Loaded 20000 samples from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\n[grpo_train] Output directory: runs/ar_rlcr_20k_nogroup/20251229_010030_ar_rlcr_20k_nogroup\n[grpo_train] Algorithm: remax\n[grpo_train] Reward mode: rlcr\n[grpo_train] Model: Qwen/Qwen3-14B\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:02<00:14,  2.10s/it]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:05<00:16,  2.71s/it]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:08<00:14,  2.88s/it]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:11<00:12,  3.01s/it]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:14<00:09,  3.09s/it]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:18<00:06,  3.14s/it]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:21<00:03,  3.23s/it]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:21<00:00,  2.36s/it]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:21<00:00,  2.74s/it]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4898, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3636, in cmd_grpo_train\n    results = train_grpo(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/train/grpo.py\", line 1037, in train_grpo\n    rec = trainer.train_step(infos=batch_infos, y=batch_y, q=batch_q)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/train/grpo.py\", line 932, in train_step\n    logp_pol, n_gen = _compute_logps_for_generated(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/train/grpo.py\", line 600, in _compute_logps_for_generated\n    out = model(sequences, attention_mask=attn)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/peft/peft_model.py\", line 1719, in forward\n    return self.base_model(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/peft/tuners/tuners_utils.py\", line 197, in forward\n    return self.model.forward(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/generic.py\", line 918, in wrapper\n    output = func(self, *args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 480, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/generic.py\", line 1072, in wrapper\n    outputs = func(self, *args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 410, in forward\n    hidden_states = decoder_layer(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/modeling_layers.py\", line 94, in __call__\n    return super().__call__(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n    return func(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 275, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 82, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/peft/tuners/lora/bnb.py\", line 518, in forward\n    output = lora_B(lora_A(dropout(x))) * scaling\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 134, in forward\n    return F.linear(input, self.weight, self.bias)\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 290.00 MiB. GPU 0 has a total capacity of 139.80 GiB of which 250.06 MiB is free. Process 1492303 has 28.45 GiB memory in use. Including non-PyTorch memory, this process has 82.71 GiB memory in use. Process 1508956 has 28.38 GiB memory in use. Of the allocated memory 79.91 GiB is allocated by PyTorch, and 2.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\ntrainable params: 64,225,280 || all params: 14,832,532,480 || trainable%: 0.4330\n", "ts": "2025-12-29T01:02:06Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 0, "id": "ar_diffusion_20k_v1", "log": "remote_logs/ar_diffusion_20k_v1.log", "pid": 1492300, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 20000 rows from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\nTrain: 16000, Test: 4000\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.82it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.77it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.74it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.74it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.73it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.73it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.72it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.07it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.86it/s]\n", "ts": "2025-12-29T02:26:04Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 1, "id": "ar_diffusion_20k_moresamples", "log": "remote_logs/ar_diffusion_20k_moresamples.log", "pid": 1506850, "tail": "[tail_error code=255] ssh: connect to host 95.133.252.72 port 22: Network is unreachable\n", "ts": "2025-12-29T02:29:19Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 0, "id": "ar_diffusion_20k_v2", "log": "remote_logs/ar_diffusion_20k_v2.log", "pid": 1508953, "tail": "[tail_error code=255] ssh: connect to host 95.133.252.72 port 22: Network is unreachable\n", "ts": "2025-12-29T02:29:19Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 1, "id": "ar_rlcr_20k_full_v1", "log": "remote_logs/ar_rlcr_20k_full_v1.log", "pid": 1551284, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n[grpo_train] Loaded 20000 samples from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\n[grpo_train] Output directory: runs/ar_rlcr_20k_full_v1/20251229_115219_ar_rlcr_20k_full_v1\n[grpo_train] Algorithm: remax\n[grpo_train] Reward mode: rlcr\n[grpo_train] Model: Qwen/Qwen3-14B\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:01<00:13,  1.99s/it]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:05<00:15,  2.59s/it]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:07<00:13,  2.77s/it]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:10<00:11,  2.85s/it]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:13<00:08,  2.91s/it]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:16<00:05,  2.92s/it]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:19<00:02,  2.93s/it]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:20<00:00,  2.15s/it]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:20<00:00,  2.54s/it]\ntrainable params: 64,225,280 || all params: 14,832,532,480 || trainable%: 0.4330\n[grpo] step 10/2000 loss=-1.5732 R=0.4127 brier=0.1967 A_std=0.2741 kl=-0.0625 fails=0 gibberish=0 time=232.6s\n[grpo] step 20/2000 loss=-0.6937 R=0.5844 brier=0.1491 A_std=0.3102 kl=0.0312 fails=0 gibberish=0 time=465.4s\n[grpo] step 30/2000 loss=1.3720 R=0.5509 brier=0.1699 A_std=0.0720 kl=0.2266 fails=0 gibberish=0 time=695.3s\n[grpo] Early stopping at step 36 (no improvement for 20 steps)\n[grpo] Best Brier: 0.0273 at step 16\n[grpo_train] Training complete!\n[grpo_train] Best Brier: 0.0273 at step 16\n[grpo_train] Saved to: runs/ar_rlcr_20k_full_v1/20251229_115219_ar_rlcr_20k_full_v1\n", "ts": "2025-12-29T12:06:50Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 1, "id": "ar_rlcr_20k_full_v2", "log": "remote_logs/ar_rlcr_20k_full_v2.log", "pid": 1557397, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n[grpo_train] Loaded 20000 samples from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\n[grpo_train] Output directory: runs/ar_rlcr_20k_full_v2/20251229_120709_ar_rlcr_20k_full_v2\n[grpo_train] Algorithm: dr_grpo\n[grpo_train] Reward mode: rlcr\n[grpo_train] Model: Qwen/Qwen3-14B\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:01<00:13,  1.97s/it]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:04<00:15,  2.58s/it]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:07<00:13,  2.78s/it]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:10<00:11,  2.86s/it]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:13<00:08,  2.90s/it]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:16<00:05,  2.93s/it]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:19<00:02,  2.92s/it]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:20<00:00,  2.15s/it]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:20<00:00,  2.54s/it]\ntrainable params: 64,225,280 || all params: 14,832,532,480 || trainable%: 0.4330\n[grpo] step 10/2000 loss=0.0370 R=0.9537 brier=0.0462 A_std=0.0213 kl=-0.0312 fails=0 gibberish=0 time=233.0s\n[grpo] step 20/2000 loss=0.7021 R=0.7228 brier=0.1052 A_std=0.3768 kl=0.2109 fails=1 gibberish=0 time=463.8s\n[grpo] Early stopping at step 30 (no improvement for 20 steps)\n[grpo] Best Brier: 0.0462 at step 10\n[grpo_train] Training complete!\n[grpo_train] Best Brier: 0.0462 at step 10\n[grpo_train] Saved to: runs/ar_rlcr_20k_full_v2/20251229_120709_ar_rlcr_20k_full_v2\n", "ts": "2025-12-29T12:32:33Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 0, "id": "ar_diffusion_20k_full_v1", "log": "remote_logs/ar_diffusion_20k_full_v1.log", "pid": 1551087, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 20000 rows from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\nTrain: 16000, Test: 4000\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.83it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.78it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.74it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.74it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.74it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.74it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.73it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.08it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.86it/s]\n", "ts": "2025-12-29T13:00:24Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 0, "id": "ar_diffusion_20k_full_v2", "log": "remote_logs/ar_diffusion_20k_full_v2.log", "pid": 1563204, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 20000 rows from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\nTrain: 16000, Test: 4000\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.81it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.76it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.73it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.73it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.72it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.72it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.71it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.06it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.85it/s]\n", "ts": "2025-12-29T13:23:28Z"}
{"done_ts": "2025-12-29T23:26:01Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "eval_rlcr_full_v2_trading", "log": "remote_logs/eval_rlcr_full_v2_trading.log", "pid": 1786466, "tail": "Traceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 479, in cached_files\n    hf_hub_download(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n    validate_repo_id(arg_value)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n    raise HFValidationError(\nhuggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'runs/ar_rlcr_20k_full_v2/20251229_121929_ar_rlcr_20k_full_v2/best'. Use `repo_type` argument if needed.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4936, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 637, in cmd_pm_eval\n    probs, llm_meta = pred.predict_proba(\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/ar_cot.py\", line 184, in predict_proba\n    self._lazy_load()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/ar_cot.py\", line 122, in _lazy_load\n    tok = AutoTokenizer.from_pretrained(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\", line 1089, in from_pretrained\n    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\", line 921, in get_tokenizer_config\n    resolved_config_file = cached_file(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 531, in cached_files\n    resolved_files = [\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 532, in <listcomp>\n    _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision, repo_type)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 143, in _get_cache_file_to_return\n    resolved_file = try_to_load_from_cache(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n    validate_repo_id(arg_value)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n    raise HFValidationError(\nhuggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'runs/ar_rlcr_20k_full_v2/20251229_121929_ar_rlcr_20k_full_v2/best'. Use `repo_type` argument if needed.\n", "ts": "2025-12-29T23:26:47Z"}
{"done_ts": "2025-12-30T00:58:58Z", "event": "failed", "exit_code": 143, "gpu": 1, "id": "eval_rlcr_full_v1_trading", "log": "remote_logs/eval_rlcr_full_v1_trading.log", "pid": 1786238, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:04,  1.51it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:04,  1.47it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:02<00:03,  1.45it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.45it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:03<00:02,  1.44it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:04<00:01,  1.44it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.43it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:05<00:00,  1.72it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:05<00:00,  1.55it/s]\nTerminated\n", "ts": "2025-12-30T00:59:12Z"}
{"done_ts": "2025-12-30T00:59:43Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "ar_diffusion_rlcr_20k_v2", "log": "remote_logs/ar_diffusion_rlcr_20k_v2.log", "pid": 1805848, "tail": "Traceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 479, in cached_files\n    hf_hub_download(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n    validate_repo_id(arg_value)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n    raise HFValidationError(\nhuggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'runs/ar_rlcr_20k_full_v2/20251229_121929_ar_rlcr_20k_full_v2/best'. Use `repo_type` argument if needed.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4936, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3720, in cmd_pm_hybrid_train\n    q_ar_train, ar_meta_train = ar_predictor.predict_proba(train_texts, K=args.ar_K, seed=args.seed)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/ar_cot.py\", line 184, in predict_proba\n    self._lazy_load()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/ar_cot.py\", line 122, in _lazy_load\n    tok = AutoTokenizer.from_pretrained(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\", line 1089, in from_pretrained\n    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\", line 921, in get_tokenizer_config\n    resolved_config_file = cached_file(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 531, in cached_files\n    resolved_files = [\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 532, in <listcomp>\n    _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision, repo_type)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 143, in _get_cache_file_to_return\n    resolved_file = try_to_load_from_cache(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n    validate_repo_id(arg_value)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n    raise HFValidationError(\nhuggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'runs/ar_rlcr_20k_full_v2/20251229_121929_ar_rlcr_20k_full_v2/best'. Use `repo_type` argument if needed.\nLoaded 20000 rows from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\nTrain: 16000, Test: 4000\n\n=== Step 1: AR Predictions ===\n", "ts": "2025-12-30T01:00:52Z"}
{"done_ts": "2025-12-30T01:02:11Z", "event": "failed", "exit_code": 143, "gpu": 0, "id": "ar_diffusion_rlcr_20k_v1", "log": "remote_logs/ar_diffusion_rlcr_20k_v1.log", "pid": 1805647, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 20000 rows from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\nTrain: 16000, Test: 4000\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.79it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.75it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.73it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.73it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.73it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.72it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.72it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.07it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.85it/s]\nTerminated\n", "ts": "2025-12-30T01:02:37Z"}
{"done_ts": "2025-12-30T01:02:38Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "ar_diffusion_5k_v2", "log": "remote_logs/ar_diffusion_5k_v2.log", "pid": 1807939, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 5000 rows from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\nTrain: 4000, Test: 1000\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.81it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.75it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.73it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.73it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.72it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.72it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:03<00:00,  2.08it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:03<00:00,  2.13it/s]\nSome parameters are on the meta device because they were offloaded to the cpu.\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4936, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3720, in cmd_pm_hybrid_train\n    q_ar_train, ar_meta_train = ar_predictor.predict_proba(train_texts, K=args.ar_K, seed=args.seed)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/ar_cot.py\", line 209, in predict_proba\n    out = model.generate(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n    return func(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2564, in generate\n    result = decoding_method(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2784, in _sample\n    outputs = self(**model_inputs, return_dict=True)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/accelerate/hooks.py\", line 175, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/generic.py\", line 918, in wrapper\n    output = func(self, *args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 494, in forward\n    logits = self.lm_head(hidden_states[:, slice_indices, :])\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/accelerate/hooks.py\", line 170, in new_forward\n    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/accelerate/hooks.py\", line 360, in pre_forward\n    set_module_tensor_to_device(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/accelerate/utils/modeling.py\", line 343, in set_module_tensor_to_device\n    new_value = value.to(device, non_blocking=non_blocking)\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 139.80 GiB of which 607.69 MiB is free. Process 1806054 has 112.80 GiB memory in use. Including non-PyTorch memory, this process has 26.40 GiB memory in use. Of the allocated memory 24.28 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n", "ts": "2025-12-30T01:12:33Z"}
{"done_ts": "2025-12-30T01:19:47Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "ar_diffusion_rlcr_5k_v2", "log": "remote_logs/ar_diffusion_rlcr_5k_v2.log", "pid": 1812468, "tail": "Traceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 479, in cached_files\n    hf_hub_download(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n    validate_repo_id(arg_value)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n    raise HFValidationError(\nhuggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'runs/ar_rlcr_20k_full_v2/20251229_121929_ar_rlcr_20k_full_v2/best'. Use `repo_type` argument if needed.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4936, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3720, in cmd_pm_hybrid_train\n    q_ar_train, ar_meta_train = ar_predictor.predict_proba(train_texts, K=args.ar_K, seed=args.seed)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/ar_cot.py\", line 184, in predict_proba\n    self._lazy_load()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/ar_cot.py\", line 122, in _lazy_load\n    tok = AutoTokenizer.from_pretrained(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\", line 1089, in from_pretrained\n    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\", line 921, in get_tokenizer_config\n    resolved_config_file = cached_file(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 531, in cached_files\n    resolved_files = [\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 532, in <listcomp>\n    _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision, repo_type)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 143, in _get_cache_file_to_return\n    resolved_file = try_to_load_from_cache(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n    validate_repo_id(arg_value)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n    raise HFValidationError(\nhuggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'runs/ar_rlcr_20k_full_v2/20251229_121929_ar_rlcr_20k_full_v2/best'. Use `repo_type` argument if needed.\nLoaded 5000 rows from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\nTrain: 4000, Test: 1000\n\n=== Step 1: AR Predictions ===\n", "ts": "2025-12-30T01:20:41Z"}
{"done_ts": "2025-12-30T01:20:58Z", "event": "failed", "exit_code": 2, "gpu": 1, "id": "eval_rlcr_5k_v2", "log": "remote_logs/eval_rlcr_5k_v2.log", "pid": 1813390, "tail": "usage: forecastbench [-h]\n                     {parity,groupstress,intrinsic_post,pm_eval,pm_eval_v2,multimarket_arb,pm_build_polydata,pm_build_subgraph,pm_download_gamma,pm_build_gamma,pm_enrich_clob,pm_download_clob_history,pm_build_horizon_prices,pm_build_criterion_prices,pm_enrich_news_gdelt,pm_difftrain,pm_diff_sample,pm_learnedCt_arb,pm_rlvr_train,pm_rlvr_eval,pm_compare,difftrain,difftrain_simplex,logical_graph,cliff_fog,group_robustness,approachability_suite,swap_regret,turtel_compare,pm_hybrid_train,synth_market,synth_headlines,pm_turtel_headlines,grpo_train,latex}\n                     ...\nforecastbench: error: unrecognized arguments: --max-rows 5000\n", "ts": "2025-12-30T01:21:55Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 1, "id": "ar_rlcr_20k_longrun", "log": "remote_logs/ar_rlcr_20k_longrun.log", "pid": 1806051, "tail": "[tail_error code=255] ssh: connect to host 95.133.252.72 port 22: Network is unreachable\n", "ts": "2025-12-30T01:45:50Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 0, "id": "ar_diffusion_5k_v1", "log": "remote_logs/ar_diffusion_5k_v1.log", "pid": 1807617, "tail": "[tail_error code=255] ssh: connect to host 95.133.252.72 port 22: Network is unreachable\n", "ts": "2025-12-30T01:45:50Z"}
{"done_ts": "2025-12-30T01:02:38Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "ar_diffusion_5k_v2", "log": "remote_logs/ar_diffusion_5k_v2.log", "pid": 2007045, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 5000 rows from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\nTrain: 4000, Test: 1000\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.81it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.76it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.74it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.74it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.71it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.72it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.72it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.06it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.85it/s]\n", "ts": "2025-12-30T10:41:17Z"}
{"done_ts": "2025-12-30T10:40:27Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "ar_diffusion_rlcr_5k_v2", "log": "remote_logs/ar_diffusion_rlcr_5k_v2.log", "pid": 2007250, "tail": "Traceback (most recent call last):\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 479, in cached_files\n    hf_hub_download(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n    validate_repo_id(arg_value)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n    raise HFValidationError(\nhuggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'runs/ar_rlcr_20k_full_v2/20251229_121929_ar_rlcr_20k_full_v2/best'. Use `repo_type` argument if needed.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 4, in <module>\n    main()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 4936, in main\n    args.func(args)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 3720, in cmd_pm_hybrid_train\n    q_ar_train, ar_meta_train = ar_predictor.predict_proba(train_texts, K=args.ar_K, seed=args.seed)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/ar_cot.py\", line 184, in predict_proba\n    self._lazy_load()\n  File \"/root/diffusion-markets/experiments/src/forecastbench/models/ar_cot.py\", line 122, in _lazy_load\n    tok = AutoTokenizer.from_pretrained(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\", line 1089, in from_pretrained\n    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\", line 921, in get_tokenizer_config\n    resolved_config_file = cached_file(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 531, in cached_files\n    resolved_files = [\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 532, in <listcomp>\n    _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision, repo_type)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/transformers/utils/hub.py\", line 143, in _get_cache_file_to_return\n    resolved_file = try_to_load_from_cache(\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n    validate_repo_id(arg_value)\n  File \"/root/diffusion-markets/experiments/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n    raise HFValidationError(\nhuggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'runs/ar_rlcr_20k_full_v2/20251229_121929_ar_rlcr_20k_full_v2/best'. Use `repo_type` argument if needed.\nLoaded 5000 rows from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet\nTrain: 4000, Test: 1000\n\n=== Step 1: AR Predictions ===\n", "ts": "2025-12-30T10:41:36Z"}
{"done_ts": "2025-12-30T10:42:01Z", "event": "failed", "exit_code": 2, "gpu": 1, "id": "eval_rlcr_longrun_pnl", "log": "remote_logs/eval_rlcr_longrun_pnl.log", "pid": 2008461, "tail": "usage: forecastbench [-h]\n                     {parity,groupstress,intrinsic_post,pm_eval,pm_eval_v2,multimarket_arb,pm_build_polydata,pm_build_subgraph,pm_download_gamma,pm_build_gamma,pm_enrich_clob,pm_download_clob_history,pm_build_horizon_prices,pm_build_criterion_prices,pm_enrich_news_gdelt,pm_difftrain,pm_diff_sample,pm_learnedCt_arb,pm_rlvr_train,pm_rlvr_eval,pm_compare,difftrain,difftrain_simplex,logical_graph,cliff_fog,group_robustness,approachability_suite,swap_regret,turtel_compare,pm_hybrid_train,synth_market,synth_headlines,pm_turtel_headlines,grpo_train,latex}\n                     ...\nforecastbench: error: unrecognized arguments: --max-rows 5000\n", "ts": "2025-12-30T10:43:19Z"}
{"done_ts": "2025-12-30T10:44:46Z", "event": "failed", "exit_code": 2, "gpu": 0, "id": "eval_rlcr_longrun_pnl_gpu0", "log": "remote_logs/eval_rlcr_longrun_pnl_gpu0.log", "pid": 2009837, "tail": "usage: forecastbench [-h]\n                     {parity,groupstress,intrinsic_post,pm_eval,pm_eval_v2,multimarket_arb,pm_build_polydata,pm_build_subgraph,pm_download_gamma,pm_build_gamma,pm_enrich_clob,pm_download_clob_history,pm_build_horizon_prices,pm_build_criterion_prices,pm_enrich_news_gdelt,pm_difftrain,pm_diff_sample,pm_learnedCt_arb,pm_rlvr_train,pm_rlvr_eval,pm_compare,difftrain,difftrain_simplex,logical_graph,cliff_fog,group_robustness,approachability_suite,swap_regret,turtel_compare,pm_hybrid_train,synth_market,synth_headlines,pm_turtel_headlines,grpo_train,latex}\n                     ...\nforecastbench: error: unrecognized arguments: --max-rows 2000\n", "ts": "2025-12-30T10:45:46Z"}
{"done_ts": "2025-12-30T10:44:52Z", "event": "failed", "exit_code": 2, "gpu": 0, "id": "eval_ar_baseline_2k", "log": "remote_logs/eval_ar_baseline_2k.log", "pid": 2009989, "tail": "usage: forecastbench [-h]\n                     {parity,groupstress,intrinsic_post,pm_eval,pm_eval_v2,multimarket_arb,pm_build_polydata,pm_build_subgraph,pm_download_gamma,pm_build_gamma,pm_enrich_clob,pm_download_clob_history,pm_build_horizon_prices,pm_build_criterion_prices,pm_enrich_news_gdelt,pm_difftrain,pm_diff_sample,pm_learnedCt_arb,pm_rlvr_train,pm_rlvr_eval,pm_compare,difftrain,difftrain_simplex,logical_graph,cliff_fog,group_robustness,approachability_suite,swap_regret,turtel_compare,pm_hybrid_train,synth_market,synth_headlines,pm_turtel_headlines,grpo_train,latex}\n                     ...\nforecastbench: error: unrecognized arguments: --max-rows 2000\n", "ts": "2025-12-30T10:46:05Z"}
{"done_ts": "2025-12-30T10:45:01Z", "event": "failed", "exit_code": 2, "gpu": 1, "id": "eval_rlcr_highgamma_pnl", "log": "remote_logs/eval_rlcr_highgamma_pnl.log", "pid": 2010107, "tail": "usage: forecastbench [-h]\n                     {parity,groupstress,intrinsic_post,pm_eval,pm_eval_v2,multimarket_arb,pm_build_polydata,pm_build_subgraph,pm_download_gamma,pm_build_gamma,pm_enrich_clob,pm_download_clob_history,pm_build_horizon_prices,pm_build_criterion_prices,pm_enrich_news_gdelt,pm_difftrain,pm_diff_sample,pm_learnedCt_arb,pm_rlvr_train,pm_rlvr_eval,pm_compare,difftrain,difftrain_simplex,logical_graph,cliff_fog,group_robustness,approachability_suite,swap_regret,turtel_compare,pm_hybrid_train,synth_market,synth_headlines,pm_turtel_headlines,grpo_train,latex}\n                     ...\nforecastbench: error: unrecognized arguments: --max-rows 2000\n", "ts": "2025-12-30T10:46:24Z"}
{"done_ts": "2025-12-30T10:46:51Z", "event": "failed", "exit_code": 2, "gpu": 0, "id": "eval_rlcr_v1_pnl_2k", "log": "remote_logs/eval_rlcr_v1_pnl_2k.log", "pid": 2011250, "tail": "usage: forecastbench [-h]\n                     {parity,groupstress,intrinsic_post,pm_eval,pm_eval_v2,multimarket_arb,pm_build_polydata,pm_build_subgraph,pm_download_gamma,pm_build_gamma,pm_enrich_clob,pm_download_clob_history,pm_build_horizon_prices,pm_build_criterion_prices,pm_enrich_news_gdelt,pm_difftrain,pm_diff_sample,pm_learnedCt_arb,pm_rlvr_train,pm_rlvr_eval,pm_compare,difftrain,difftrain_simplex,logical_graph,cliff_fog,group_robustness,approachability_suite,swap_regret,turtel_compare,pm_hybrid_train,synth_market,synth_headlines,pm_turtel_headlines,grpo_train,latex}\n                     ...\nforecastbench: error: unrecognized arguments: --max-rows 2000\n", "ts": "2025-12-30T10:47:32Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 0, "id": "pm_hybrid_train_seed100", "log": "remote_logs/pm_hybrid_train_seed100.log", "pid": 2133047, "tail": "[tail_error code=255] ssh: connect to host 95.133.252.72 port 22: Network is unreachable\n", "ts": "2025-12-30T21:37:57Z"}
{"done_ts": "2025-12-31T00:11:49Z", "event": "failed", "exit_code": 2, "gpu": 0, "id": "rlcr_fixed_v1", "log": "remote_logs/rlcr_fixed_v1.log", "pid": 2360614, "tail": "usage: forecastbench [-h]\n                     {parity,groupstress,intrinsic_post,pm_eval,pm_eval_v2,multimarket_arb,pm_build_polydata,pm_build_subgraph,pm_download_gamma,pm_build_gamma,pm_enrich_clob,pm_download_clob_history,pm_build_horizon_prices,pm_build_criterion_prices,pm_enrich_news_gdelt,pm_difftrain,pm_diff_sample,pm_learnedCt_arb,pm_rlvr_train,pm_rlvr_eval,pm_compare,difftrain,difftrain_simplex,logical_graph,cliff_fog,group_robustness,approachability_suite,swap_regret,turtel_compare,pm_hybrid_train,synth_market,synth_headlines,pm_turtel_headlines,grpo_train,latex}\n                     ...\nforecastbench: error: unrecognized arguments: --n-samples 5000\n", "ts": "2025-12-31T00:12:30Z"}
{"done_ts": "2025-12-31T00:11:55Z", "event": "failed", "exit_code": 2, "gpu": 1, "id": "rlcr_fixed_gamma1", "log": "remote_logs/rlcr_fixed_gamma1.log", "pid": 2360764, "tail": "usage: forecastbench [-h]\n                     {parity,groupstress,intrinsic_post,pm_eval,pm_eval_v2,multimarket_arb,pm_build_polydata,pm_build_subgraph,pm_download_gamma,pm_build_gamma,pm_enrich_clob,pm_download_clob_history,pm_build_horizon_prices,pm_build_criterion_prices,pm_enrich_news_gdelt,pm_difftrain,pm_diff_sample,pm_learnedCt_arb,pm_rlvr_train,pm_rlvr_eval,pm_compare,difftrain,difftrain_simplex,logical_graph,cliff_fog,group_robustness,approachability_suite,swap_regret,turtel_compare,pm_hybrid_train,synth_market,synth_headlines,pm_turtel_headlines,grpo_train,latex}\n                     ...\nforecastbench: error: unrecognized arguments: --n-samples 5000\n", "ts": "2025-12-31T00:12:42Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 0, "id": "eval_rlcr_fixed_v1", "log": "remote_logs/eval_rlcr_fixed_v1.log", "pid": 2373480, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.81it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.76it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.73it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.73it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.72it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.72it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.71it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.06it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.85it/s]\n", "ts": "2025-12-31T04:08:59Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 1, "id": "eval_ar_baseline_full", "log": "remote_logs/eval_ar_baseline_full.log", "pid": 2422614, "tail": "[tail_error code=255] ssh: connect to host 95.133.252.72 port 22: Network is unreachable\n", "ts": "2025-12-31T06:44:57Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 0, "id": "eval_rlcr_fixed_20k", "log": "remote_logs/eval_rlcr_fixed_20k.log", "pid": 2461072, "tail": "[tail_error code=255] ssh: connect to host 95.133.252.72 port 22: Network is unreachable\n", "ts": "2025-12-31T07:22:17Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 0, "id": "pm_hybrid_train_seed102", "log": "remote_logs/pm_hybrid_train_seed102.log", "pid": 2560996, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\nLoaded 1500 rows from /root/polymarket_data/derived/gamma_yesno_ready.parquet\nTrain: 1200, Test: 300\n\n=== Step 1: AR Predictions ===\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.81it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.76it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.73it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.73it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.73it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.72it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.72it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.07it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.85it/s]\n", "ts": "2025-12-31T13:49:32Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 1, "id": "eval_ar_baseline_20k", "log": "remote_logs/eval_ar_baseline_20k.log", "pid": 2539533, "tail": "[tail_error code=255] ssh: connect to host 95.133.252.72 port 22: Network is unreachable\n", "ts": "2025-12-31T23:27:33Z"}
{"done_ts": "2026-01-01T04:41:16Z", "event": "failed", "exit_code": 143, "gpu": 0, "id": "rlcr_ct_analysis_longrun", "log": "remote_logs/rlcr_ct_analysis_longrun.log", "pid": 2831295, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n======================================================================\nRLCR C_t APPROXIMATION ERROR ANALYSIS\n======================================================================\n\nLoading data from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet...\nUsing 1000 examples\nOutcome rate: 29.0%\nMarket price range: [0.004, 0.996]\nLoading RLCR model from runs/ar_rlcr_20k_longrun/20251230_005945_ar_rlcr_20k_longrun/best...\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.81it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.75it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.73it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.72it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.72it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.71it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.71it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.06it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.84it/s]\nTerminated\n", "ts": "2026-01-01T04:41:41Z"}
{"done_ts": "2026-01-01T04:41:16Z", "event": "failed", "exit_code": 143, "gpu": 1, "id": "rlcr_ct_analysis_fixed_v1", "log": "remote_logs/rlcr_ct_analysis_fixed_v1.log", "pid": 2832067, "tail": "`torch_dtype` is deprecated! Use `dtype` instead!\n======================================================================\nRLCR C_t APPROXIMATION ERROR ANALYSIS\n======================================================================\n\nLoading data from polymarket_backups/pm_suite_derived/gamma_yesno_ready_20k.parquet...\nUsing 1000 examples\nOutcome rate: 29.0%\nMarket price range: [0.004, 0.996]\nLoading RLCR model from runs/grpo/20251231_002357_rlcr_fixed_v1/best...\n\nLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\nLoading checkpoint shards:  12%|\u2588\u258e        | 1/8 [00:00<00:03,  1.81it/s]\nLoading checkpoint shards:  25%|\u2588\u2588\u258c       | 2/8 [00:01<00:03,  1.76it/s]\nLoading checkpoint shards:  38%|\u2588\u2588\u2588\u258a      | 3/8 [00:01<00:02,  1.73it/s]\nLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588     | 4/8 [00:02<00:02,  1.73it/s]\nLoading checkpoint shards:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 5/8 [00:02<00:01,  1.72it/s]\nLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 6/8 [00:03<00:01,  1.72it/s]\nLoading checkpoint shards:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 7/8 [00:04<00:00,  1.71it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  2.06it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:04<00:00,  1.85it/s]\nTerminated\n", "ts": "2026-01-01T04:41:53Z"}
{"done_ts": "2026-01-01T08:11:52Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "pm_hybrid_train_gpu1_seed103", "log": "remote_logs/pm_hybrid_train_gpu1_seed103.log", "pid": 2918274, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 1, in <module>\n    from forecastbench.cli import main\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 9, in <module>\n    import matplotlib.pyplot as plt\nModuleNotFoundError: No module named 'matplotlib'\n", "ts": "2026-01-01T08:12:34Z"}
{"done_ts": "2026-01-01T08:13:41Z", "event": "failed", "exit_code": 1, "gpu": 1, "id": "pm_difftrain_gpu1_seed104", "log": "remote_logs/pm_difftrain_gpu1_seed104.log", "pid": 2919174, "tail": "Traceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/root/diffusion-markets/experiments/src/forecastbench/__main__.py\", line 1, in <module>\n    from forecastbench.cli import main\n  File \"/root/diffusion-markets/experiments/src/forecastbench/cli.py\", line 9, in <module>\n    import matplotlib.pyplot as plt\nModuleNotFoundError: No module named 'matplotlib'\n", "ts": "2026-01-01T08:14:24Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 0, "id": "clustering_optimization_v1", "log": "remote_logs/clustering_optimization_v1.log", "pid": 3290641, "tail": "[tail_error code=255] ssh: connect to host 95.133.252.72 port 22: Network is unreachable\n", "ts": "2026-01-01T23:35:06Z"}
{"done_ts": null, "event": "failed_legacy", "exit_code": null, "gpu": 1, "id": "clustering_optimization_full", "log": "remote_logs/clustering_optimization_full.log", "pid": 3290820, "tail": "[tail_error code=255] ssh: connect to host 95.133.252.72 port 22: Network is unreachable\n", "ts": "2026-01-01T23:35:06Z"}
